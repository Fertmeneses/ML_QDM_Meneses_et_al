{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65f67b14",
   "metadata": {},
   "source": [
    "# Elevator/AI Experiment: Auxiliar functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6034eea0-89df-47d2-9674-0f657f577467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "from numpy import linalg as LA\n",
    "import random\n",
    "import copy\n",
    "import time\n",
    "\n",
    "# Plot parameters:\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import seaborn as sns\n",
    "\n",
    "markers = [\"o\",\"<\",\"s\",\"d\",\"v\",\"p\",\"P\",\"^\",\"*\",\"D\",\">\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b1487b5-9378-4af5-bd9e-8034a8f22746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_3D(vector,n,theta_deg):\n",
    "    \"\"\"\n",
    "    Rotates a vector or matrix by an angle theta around the axis n.\n",
    "\n",
    "    --- Inputs ---\n",
    "    \n",
    "    {vector}: Vector to be rotated, must be a numpy array with three rows (x,y,z).\n",
    "    {n}: Rotation axis, must be provided as a numpy array with 3 elements (x,y,z). No normalisation\n",
    "    needed at this stage.\n",
    "    {theta_deg}: Rotation angle in [degrees].\n",
    "    \n",
    "    --- Outputs ---\n",
    "    \n",
    "    {vector_R}: Numpy array; Rotated vector or matrix.\n",
    "    \"\"\"\n",
    "    # Normalise u and convert angle to [rad]:\n",
    "    u = n/LA.norm(n) # Normalised unit vector\n",
    "    ux, uy, uz = u[0], u[1], u[2] # Cartesian components\n",
    "    theta = theta_deg/360*2*np.pi # Rotation angle [rad]\n",
    "    # Define the rotation matrix:\n",
    "    c = np.cos(theta)\n",
    "    q = 1-c\n",
    "    s = np.sin(theta)\n",
    "    R = np.array([[c+ux**2*q,ux*uy*q-uz*s,ux*uz*q+uy*s],\n",
    "                  [uy*ux*q+uz*s,c+uy**2*q,uy*uz*q-ux*s],\n",
    "                  [uz*ux*q-uy*s,ux*uy*q+ux*s,c+uz**2*q]\n",
    "    ])\n",
    "    return np.matmul(R,vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c32fbd1b-c7a7-4e02-be81-dccc23339f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulations:\n",
    "\n",
    "mu0 = 1.256637e-16 # Vacuum permeability, SI units [N/A^2]\n",
    "def single_dipole(r_traj,m_vec):\n",
    "    \"\"\"\n",
    "    Calculate the vector magnetic field produced by a single dipole with magnetic moment m_vec at a \n",
    "    distance r_traj.\n",
    "    {r_traj}: Numpy array; (x,y,z) elevator's trajectory sensed by the magnetometer. The output format has\n",
    "    three rows, corresponding to (x,y,z), and each column is a timestep dt=1/{f_samp}. Units are [m].\n",
    "    {m_vec} = Magnetic moment for the dipole. It must be a numpy array or list in the laboratory frame\n",
    "    with format (X,Y,Z) [A*m^2]\n",
    "    --- Returns ---\n",
    "    {B_sd}: Numpy array; magnetic stray fields sensed by the magnetometer during the elevator's trajectory.\n",
    "    The output format has three rows, corresponding to (Bx,By,Bz), and each column is a timestep correlated\n",
    "    with the {r_traj} vector. Units are [T].\n",
    "    \"\"\"\n",
    "    # Calculate modulus series [m]:\n",
    "    r = np.sqrt(r_traj[0]*r_traj[0]+r_traj[1]*r_traj[1]+r_traj[2]*r_traj[2]) # Modulus series [m]\n",
    "\n",
    "    # Calculate stray fields series:\n",
    "    B_sd = 3*r_traj*np.dot(m_vec,r_traj)/r**5 # First term [A/m]\n",
    "    B_sd += np.array([m_vec[0]/r**3,m_vec[1]/r**3,m_vec[2]/r**3]) # Add the second term [A/m]\n",
    "    B_sd *= mu0/(4*np.pi) # Scale it to appropriate units [T].\n",
    "\n",
    "    return B_sd\n",
    "\n",
    "def optimize_sims_2SD(t,z,r1,r2,exp_data,m1_grid,m2_grid,d_12=28):\n",
    "    \"\"\"\n",
    "    Optimizes the parameters used in 2-single-dipoles simulations to reproduce experimental measurements.\n",
    "    * Note: the coordinates system is centered at the elevator's door at level 0, and the z-axis is solidary with\n",
    "    the elevator's axis, poiting upwards.\n",
    "    --- Inputs ---        \n",
    "    {t}: Numpy array; time vector with uniform time steps [s].,\n",
    "    {z}: Numpy array; z-position vector for the elevator's cage [m].\n",
    "    {r1,r2}: Lists or numpy arrays; sensor position in (X,Y,Z) format, in [m], seen from the\n",
    "    dipoles number 1 and number 2, respectively, when they are closest to the sensor.\n",
    "    {d_12}: Float; maximum distance between the cage and counterweight [m]. Default: 28m.\n",
    "    {exp_comp}: Dataframe with the following columns: 'Time_s', 'Bx_nT','By_nT','Bz_nT'; experimental\n",
    "    measurements which simulations try to reproduce.\n",
    "    {m1_grid,m2_grid}: List whose elements are Numpy arrays; each element is an option for the magnetic moments in \n",
    "    (mx,my,mz) format, in [A*m^2], for the two single dipoles.\n",
    "    --- Outputs ---\n",
    "    \"\"\"\n",
    "    # Translate the z-pos vector so it tracks the magnetometer position seen from the elevator's elements:\n",
    "    r1_traj = np.array([np.linspace(-r1[0],-r1[0],len(z)),np.linspace(-r1[1],-r1[1],len(z)),-z]) # [m]\n",
    "    r2_traj = np.array([np.linspace(-r2[0],-r2[0],len(z)),np.linspace(-r2[1],-r2[1],len(z)),z-d_12]) # [m]\n",
    "\n",
    "    best_sum_dif = np.inf # Initiate scoring (worst possible result) [nT]\n",
    "    best_config = [0,0]\n",
    "    for m1 in m1_grid:\n",
    "        for m2 in m2_grid:\n",
    "            # Calculate the stray fields (Bx,By,Bz) sensed by the magnetometer:\n",
    "            B1 = single_dipole(r1_traj,m1)*1e9 # Magnetic fields originated by the cage [nT]\n",
    "            B2 = single_dipole(r2_traj,m2)*1e9 # Magnetic fields originated by the counterweight [nT]\n",
    "            B = B1 + B2 # Total magnetic field [nT]\n",
    "            # Evaluate simulationa and keep best parameters:\n",
    "            sum_dif = np.sum(np.abs(B[0]-exp_data['Bx_nT']))*10 \\\n",
    "            + np.sum(np.abs(B[1]-exp_data['Bx_nT'])) \\\n",
    "            + np.sum(np.abs(B[2]-exp_data['Bz_nT'])) # [nT]\n",
    "            if sum_dif < best_sum_dif:\n",
    "                best_sum_dif = sum_dif\n",
    "                best_config = [m1,m2]\n",
    "                \n",
    "    return best_config[0], best_config[1]\n",
    "\n",
    "def sim_B_2SD(t,z,m1,m2,r1,r2,noise_X,noise_YZ,d_12=28,exp_comp=None,t_zoom=None,\n",
    "              save_name=None,save_format='png'):    \n",
    "    \"\"\"\n",
    "    Simulates the stray magnetic fields sensed by the magnetometer according to a two-single-dipoles model\n",
    "    (symbolyzing the elevator's cage and the counterweight) and plots the cage and counterweight trajectories\n",
    "    along with the sensed stray magnetic fields.\n",
    "    * Note: the coordinates system is centered at the elevator's door at level 0, and the z-axis is solidary with\n",
    "    the elevator's axis, poiting upwards.\n",
    "    {t}: Numpy array; time vector with uniform time steps [s].,\n",
    "    {z}: Numpy array; z-position vector for the elevator's cage [m].\n",
    "    {m1,m2}: Numpy arrays; magnetic moments in (mx,my,mz) format, in [A*m^2] for the two different single\n",
    "    dipoles. They are assumed to be constant.\n",
    "    {r1,r2}: Lists or numpy arrays; sensor position in (X,Y,Z) format, in [m], seen from the\n",
    "    dipoles number 1 and number 2, respectively.\n",
    "    {d_12}: Float; maximum distance between the cage and counterweight [m]. Default: 28m.\n",
    "    {noise_X}: Float; noise standard deviation (Gaussian distribution) along X-component, mean=0, in [nT].\n",
    "    {noise_YZ}: Float; noise standard deviation (Gaussian distribution) along X,Y-components, mean=0, in [nT].\n",
    "    {t_zoom}: List, numpy array or None. If None (default), the entire time range will be plotted. If values\n",
    "    are provided, the time range will be restricted to t_zoom[0] to t_zoom[1], units [s].\n",
    "    {exp_comp}: Dataframe with the following columns: 'Time_s', 'Bx_nT','By_nT','Bz_nT'.\n",
    "    If provided, it will be used to compare with the simulations. If None (default), there is no comparison.\n",
    "    {save_name}: String that allows to save the figure in the selected path. Format is .png by default.\n",
    "    {save_format}: Chooses the format to save the figure, don't include the dot. Default: 'png'.\n",
    "    \"\"\"\n",
    "    # Translate the z-pos vector so it tracks the magnetometer position seen from the elevator's elements:\n",
    "    r1_traj = np.array([np.linspace(-r1[0],-r1[0],len(z)),np.linspace(-r1[1],-r1[1],len(z)),-z]) # [m]\n",
    "    r2_traj = np.array([np.linspace(-r2[0],-r2[0],len(z)),np.linspace(-r2[1],-r2[1],len(z)),z-d_12]) # [m]  \n",
    "    # Calculate the stray fields (Bx,By,Bz) sensed by the magnetometer:\n",
    "    B1 = single_dipole(r1_traj,m1)*1e9 # Magnetic fields originated by the cage [nT]\n",
    "    B2 = single_dipole(r2_traj,m2)*1e9 # Magnetic fields originated by the counterweight [nT]\n",
    "    B = B1 + B2 # Total magnetic field [nT]\n",
    "    # Add magnetic noise:\n",
    "    B[0,:] += np.random.normal(loc=0.0, scale=noise_X, size=len(B[0])) # X-comp [nT]\n",
    "    B[1,:] += np.random.normal(loc=0.0, scale=noise_YZ, size=len(B[1])) # Y-comp [nT]\n",
    "    B[2,:] += np.random.normal(loc=0.0, scale=noise_YZ, size=len(B[2])) # Z-comp [nT] \n",
    "    \n",
    "    # Plot the trajectory and magnetic fields seen and sensed by the magnetometer:\n",
    "    fig = plt.figure(figsize=(6,4))\n",
    "    gs = fig.add_gridspec(3, 2, hspace=0, wspace=0.5)\n",
    "    (ax_X, ax_Bx), (ax_Y, ax_By), (ax_Z, ax_Bz) = gs.subplots(sharex='col')\n",
    "    axes_pos, axes_B = [ax_X, ax_Y, ax_Z], [ax_Bx, ax_By, ax_Bz]\n",
    "    ylabels_pos = ['$X$ [m]','$Y$ [m]','$Z$ [m]']\n",
    "    ylabels_B = ['$B_{X}$ [nT]','$B_{Y}$ [nT]','$B_{Z}$ [nT]']\n",
    "    colors = ['#33a1ffff','#3349ffff','#a433ffff'] # Bx, By, Bz\n",
    "    for i in range(len(axes_pos)): # Trajectory\n",
    "        axes_pos[i].plot(t,-r1_traj[i],'-',lw=1,color='#367642ff',label='Cage',alpha=1)\n",
    "        axes_pos[i].plot(t,-r2_traj[i],'--',lw=1,color='#19b436ff',label='Ctwt',alpha=0.9)\n",
    "        axes_pos[i].set_ylabel(ylabels_pos[i])\n",
    "        axes_pos[i].legend(fontsize=6)\n",
    "        if i == 0 or i == 1:\n",
    "            axes_pos[i].set_yticks([r1[i],r2[i]])\n",
    "    for i in range(len(axes_B)): # Stray fields\n",
    "        axes_B[i].plot(t,B[i],color=colors[i],alpha=1,label='Sim.')\n",
    "        axes_B[i].set_ylabel(ylabels_B[i])\n",
    "        if exp_comp is not None: # If provided, compare with experiments\n",
    "            comp = ['Bx_nT','By_nT','Bz_nT'][i]\n",
    "            axes_B[i].plot(exp_comp['Time_s'],exp_comp[comp]-(exp_comp[comp].iloc[0]-B[i][0]),'o',color='gray',\n",
    "                           alpha=0.7,markersize=0.3,label='Exp.')\n",
    "        axes_B[i].legend(fontsize=6)\n",
    "    if isinstance(t_zoom,(list,np.ndarray)): # If provided, set y limits\n",
    "        for ax in axes_pos+axes_B:\n",
    "            ax.set_xlim([t_zoom[0],t_zoom[1]])\n",
    "    axes_pos[-1].set_xlabel(f'Time [s]')    \n",
    "    axes_B[-1].set_xlabel(f'Time [s]')\n",
    "    if save_name:\n",
    "        save_file(save_name,save_format=save_format)    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3121e0b0-86a2-4045-8e0b-e18ea03b8e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Time_Wdw:\n",
    "    \"\"\"\n",
    "    The Time Window object <Time_Wdw> can process an input dataframe with information about time, magnetic fields,\n",
    "    z-position labels and optionally the ground truth z-position labels, all given in the Laboratory rotational\n",
    "    frame, defined as RF1. <Time_Wdw> can return numpy arrays representing time windows for the magnetic projections\n",
    "    Bx, By and Bz, in the requested rotational frame. All time windows will be correlated to z-position labels, and\n",
    "    eventually to the ground truth labels, if they were provided in the input dataframe.\n",
    "\n",
    "    --- Attributes ---\n",
    "    \n",
    "    GENERAL:\n",
    "    {self.name}: String; name for the <Time_Wdw> object.\n",
    "    {self.pp}: Integer; number of points for each time window.\n",
    "    {self.gr_tr}: Boolean; specifies whether the ground truth labels are included (True) or not (False).\n",
    "    {self.rotFrame}: List [Numpy array,Numeric,String]; specifies the rotated frame that is currently active for time\n",
    "    windowing. The elements of the list are the following: [rotation axis in (x,y,z) format,rotation\n",
    "    angle in degree units,  RF name]. By default, the rotated frame is the original lab frame,\n",
    "    then [None,None,'RF1'].\n",
    "    {self.norm_value}: Float; normalizing value for future reference, in [nT] units.\n",
    "    ORIGINAL DATA:\n",
    "    {self.time}: Numpy array; time vector from the original data, before windowing. Units: s.\n",
    "    {self.z}: Numpy array: z-position vector from the original data, before windowing. Units: m.\n",
    "    {self.Bx_RF1}: Numpy array; Bx vector from the original data in RF1, before windowing. Units: nT.\n",
    "    {self.By_RF1}: Numpy array; By vector from the original data in RF1, before windowing. Units: nT.\n",
    "    {self.Bz_RF1}: Numpy array; Bz vector from the original data in RF1, before windowing. Units: nT.\n",
    "    {self.B_RF1}: Numpy array; calculated B (scalar) vector from the original data, before windowing. Units: nT.\n",
    "    WINDOWED DATA:\n",
    "    The following attributes are Numpy arrays containing the time windows' information. Each time window instance is\n",
    "    stored as a row with self.pp points. Then, the matrix has a size (N x self.pp), where N is the number of time windows. \n",
    "    {self.time_wdw}: Numpy array; time matrix. Units: s.\n",
    "    {self.Bx_wdw_RF1}: Numpy array; Bx matrix in RF1. Units: nT.\n",
    "    {self.By_wdw_RF1}: Numpy array; By matrix in RF1. Units: nT.\n",
    "    {self.Bz_wdw_RF1}: Numpy array; Bz matrix in RF1. Units: nT.\n",
    "    {self.B_wdw}: Numpy array; B (scalar) matrix (rotational invariant). Units: nT.\n",
    "    {self.Bx_wdw_RFX}: Numpy array; Bx matrix in the current rotated frame self.rotFrame, if any. Units: nT.\n",
    "    {self.By_wdw_RFX}: Numpy array; By matrix in the current rotated frame self.rotFrame, if any. Units: nT.\n",
    "    {self.Bz_wdw_RFX}: Numpy array; Bz matrix in the current rotated frame self.rotFrame, if any. Units: nT.\n",
    "    {self.z_labels}: Numpy array; z-position vector from the original data, after windowing. Units: m.\n",
    "    Note: windowed data can be augmented artificially, in which case the new augmented data will replace the previous\n",
    "    attributes, but original data (not windowed) will remain the same.\n",
    "    {self.augm_N}: Integer; specifies how many times the data was artificially augmented (if there\n",
    "    is no augmentation, then augm_N=0).\n",
    "    {self.augm_noise}: List [Bx_noise, By_noise, Bz_noise]; each element specifies the noise level\n",
    "    which was used to augmentate the data, in [nT], for the [Bx,By,Bz] original data in RF1.\n",
    "    \"\"\"\n",
    "    def __init__(self, pp, name, gr_tr=False):\n",
    "        \"\"\"\n",
    "        --- Inputs ---\n",
    "        {pp}: Integer; number of points for each time window.\n",
    "        {name}: String; name for the <Time_Wdw> object, it may contain the segment number.\n",
    "        {gr_tr}: Boolean; specifies whether the <Time_Wdw> object is labeled according to\n",
    "        the ground truth (True) or not (False, default).\n",
    "        \"\"\"\n",
    "        self.name = name # Name\n",
    "        self.pp = pp # Number of points for every time window\n",
    "        self.gr_tr = gr_tr # Informs whether ground truth is available (True) or not (False)\n",
    "        self.rotFrame = [None,None,'RF1'] # At the beginning, there is no rotated frame\n",
    "\n",
    "    def store_orig_data(self, df):\n",
    "        \"\"\"\n",
    "        Receives a dataframe with the measurements data (t,Bx,By,Bz,z), eventually z_true as \n",
    "        well, in RF1. If <self.gr_tr>=True, then it will be assumed that the dataframe \n",
    "        includes the ground truth labels.        \n",
    "        --- Inputs ---        \n",
    "        {df}: Pandas dataframe; it must have the following columns: 'Time_s', 'Bx_nT', 'By_nT',\n",
    "        'Bz_nT', 'zAut_m' and, optionally, 'zTrue_m'.\n",
    "        \"\"\"\n",
    "        # Prepare and store original data, except z: t, Bx, By, Bz, B (scalar)\n",
    "        t, Bx, By, Bz = df['Time_s'], df['Bx_nT'], df['By_nT'], df['Bz_nT'] # [s,nT,nT,nT]\n",
    "        self.time = t.to_numpy() # Time [s]\n",
    "        self.Bx_RF1 = Bx.to_numpy() # Bx fields in RF1 [nT]\n",
    "        self.By_RF1 = By.to_numpy() # By fields in RF1 [nT]\n",
    "        self.Bz_RF1 = Bz.to_numpy() # Bz fields in RF1 [nT]\n",
    "        self.B_RF1 = np.sqrt(self.Bx_RF1**2 + self.By_RF1**2 + self.Bz_RF1**2) # Scalar B field [nT]\n",
    "        # Store z-position, using the ground truth when available:\n",
    "        z = df['zTrue_m'] if self.gr_tr else df['zAut_m'] # [m]\n",
    "        self.z = z.to_numpy() # Z-position [m]\n",
    "    \n",
    "    def window_data(self, N_augm=0, Bx_noise=1, By_noise=1, Bz_noise=1):\n",
    "        \"\"\"\n",
    "        Generates time windows in the original dataframe RF1, with predictors\n",
    "        (magnetic fields) and targets (z-pos) from the original data according to the \n",
    "        attributes <self.pp> and <self.dp>, with the possibility of augmentating the data\n",
    "        using random noise.\n",
    "        --- Inputs ---\n",
    "        {N_augm}: Integer; specifies how many times the data will be augmented. If 0 (default),\n",
    "        there will be no augmentation.\n",
    "        {Bx_noise}: Float; value for the standard deviation in the random normal distribution,\n",
    "        in [nT] units. Default: 1 nT.\n",
    "        {By_noise, Bz_noise}: idem noise_Bx, but for By and Bz components. Default: 1 nT.\n",
    "        WARNING: This function will only work if the original data was previously stored.\n",
    "        \"\"\"\n",
    "        # Store the [time, Bx, By, Bz, B, z] time windows and labels in RF1:\n",
    "        N = len(self.z)-self.pp # Total number of time windows\n",
    "        self.time_wdw = np.array([np.array(self.time[i:i+self.pp]) for i in range(N)]) # Store times [s]\n",
    "        self.Bx_wdw_RF1 = np.array([self.Bx_RF1[i:i+self.pp] for i in range(N)]) # Store Bx fields windows in RF1 [nT]\n",
    "        self.By_wdw_RF1 = np.array([self.By_RF1[i:i+self.pp] for i in range(N)]) # Store By fields windows in RF1 [nT]\n",
    "        self.Bz_wdw_RF1 = np.array([self.Bz_RF1[i:i+self.pp] for i in range(N)]) # Store Bz fields windows in RF1 [nT]\n",
    "        self.B_wdw = np.array([self.B_RF1[i:i+self.pp] for i in range(N)]) # Store scalar B fields windows [nT]\n",
    "        self.z_labels = self.z[self.pp:] # z-position labels, for time windows [m]\n",
    "\n",
    "        # Augmentate data if required:\n",
    "        self.augm_N = N_augm # State how many times the data was augmented\n",
    "        self.augm_noise = [Bx_noise,By_noise,Bz_noise] # State the augmentation noise levels [nT]\n",
    "        if N_augm:\n",
    "            # Initiate augmentated data with the original windows:\n",
    "            Bx_wdw_augm = np.copy(self.Bx_wdw_RF1) # [nT]\n",
    "            By_wdw_augm = np.copy(self.By_wdw_RF1) # [nT]\n",
    "            Bz_wdw_augm = np.copy(self.Bz_wdw_RF1) # [nT]\n",
    "            B_wdw_augm = np.copy(self.B_wdw) # [nT]\n",
    "            z_labels_augm = np.copy(self.z_labels) # [m]\n",
    "            # Determine noise factor for scalar B:\n",
    "            B_noise = np.sqrt(Bx_noise**2+By_noise**2+Bz_noise**2) # [nT]\n",
    "            # Augmentate data\n",
    "            for i in range(N_augm):\n",
    "                # Generate random noise matrices:\n",
    "                new_Bx_wdw = self.Bx_wdw_RF1+np.random.normal(size=self.Bx_wdw_RF1.shape)*Bx_noise # [nT]\n",
    "                new_By_wdw = self.By_wdw_RF1+np.random.normal(size=self.By_wdw_RF1.shape)*By_noise # [nT]\n",
    "                new_Bz_wdw = self.Bz_wdw_RF1+np.random.normal(size=self.Bz_wdw_RF1.shape)*Bz_noise # [nT]\n",
    "                new_B_wdw = self.B_wdw+np.random.normal(size=self.B_wdw.shape)*B_noise # [nT]\n",
    "                # Augmentate windowed data:\n",
    "                Bx_wdw_augm = np.vstack([Bx_wdw_augm,new_Bx_wdw]) # [nT]\n",
    "                By_wdw_augm = np.vstack([By_wdw_augm,new_By_wdw]) # [nT]\n",
    "                Bz_wdw_augm = np.vstack([Bz_wdw_augm,new_Bz_wdw]) # [nT]\n",
    "                B_wdw_augm = np.vstack([B_wdw_augm,new_B_wdw]) # [nT]\n",
    "                z_labels_augm = np.hstack([z_labels_augm,self.z_labels]) # [m]\n",
    "            # Update attributes:    \n",
    "            self.Bx_wdw_RF1 = Bx_wdw_augm # Update windowed data [nT]\n",
    "            self.By_wdw_RF1 = By_wdw_augm # Update windowed data [nT]\n",
    "            self.Bz_wdw_RF1 = Bz_wdw_augm # Update windowed data [nT]\n",
    "            self.B_wdw = B_wdw_augm # Update windowed data [nT]\n",
    "            self.z_labels = z_labels_augm # Update windowed data [m]\n",
    "\n",
    "    def rotate_frame(self,RF_info):\n",
    "        \"\"\"\n",
    "        Generates time windows in a rotated frame, labeled as \"RFX\" in the object's attributes.\n",
    "        Only one rotated frame can be recorded at a time.        \n",
    "        --- Inputs ---        \n",
    "        {RF_info}: List [Numpy array,Numeric,String]; specifies the rotated frame that is currently stored. The elements\n",
    "        of the list are the following: [rotation axis in (x,y,z) format,rotation angle in degree units,  RF name]. If\n",
    "        RF_info[2] == 'RF1', then the data is kept in the original frame.\n",
    "        \"\"\"\n",
    "        n_vec, theta_deg, RF_name = RF_info[0], RF_info[1], RF_info[2]\n",
    "        self.rotFrame = [n_vec,theta_deg,RF_name] # RFX information: rotation axis, rotation angle [degree], name\n",
    "        # Keep original frame:\n",
    "        if RF_name == 'RF1':\n",
    "            self.Bx_wdw_RFX = self.Bx_wdw_RF1\n",
    "            self.By_wdw_RFX = self.By_wdw_RF1\n",
    "            self.Bz_wdw_RFX = self.Bz_wdw_RF1\n",
    "        else:\n",
    "            # Rotate original information (RF1), window by window:\n",
    "            # {vector}: Vector to be rotated, must be a numpy array with three rows (x,y,z).\n",
    "            # Initiate:\n",
    "            self.Bx_wdw_RFX = np.empty(shape=(self.Bx_wdw_RF1.shape))\n",
    "            self.By_wdw_RFX = np.empty(shape=(self.By_wdw_RF1.shape))\n",
    "            self.Bz_wdw_RFX = np.empty(shape=(self.Bz_wdw_RF1.shape))\n",
    "            for i in range(len(self.Bx_wdw_RF1)):\n",
    "                v_rot = rotate_3D(np.array([self.Bx_wdw_RF1[i],self.By_wdw_RF1[i],self.Bz_wdw_RF1[i]]),\n",
    "                                  n_vec,theta_deg) # Rotated fields Bx', By', Bz' [nT]\n",
    "                self.Bx_wdw_RFX[i] = v_rot[0] # [nT]\n",
    "                self.By_wdw_RFX[i] = v_rot[1] # [nT]\n",
    "                self.Bz_wdw_RFX[i] = v_rot[2] # [nT]\n",
    "    \n",
    "    def info(self):\n",
    "        \"\"\"\n",
    "        Prints in screen a summary of the object.\n",
    "        \"\"\"\n",
    "        print('-'*30)\n",
    "        print('Time window object - Summary:')\n",
    "        print('Name:',self.name)\n",
    "        print('Points in each time window:',self.pp)\n",
    "        print('Ground truth available:',self.gr_tr)\n",
    "        if 'z_labels' in dir(self):\n",
    "            print('Number of windows:',len(self.z_labels))\n",
    "        print('Rotated Frame:',self.rotFrame[2])\n",
    "        if 'augm_N' in dir(self):\n",
    "            print(f'Data was augmented {self.augm_N} times.')\n",
    "            print(f'Augmentation noise levels in RF1 (Bx,By,Bz): ({self.augm_noise}) nT')\n",
    "        else:\n",
    "            print('No data augmentation')\n",
    "        print('-'*30)\n",
    "\n",
    "    def plot_instances(self,stride_pp=None,start_wdw=0,RF=False,instances=5,\n",
    "                       savefig=None,save_format='png'):\n",
    "        \"\"\"\n",
    "        Plots some instances of time windows along with z-position labels.\n",
    "        \n",
    "        --- Inputs ---\n",
    "        \n",
    "        {stride_pp}: Integer; number of points by which the time windows' first point will be spaced in the plot.\n",
    "        If None (default), then it will be chosen automatically.\n",
    "        {start_pp}: Integer; first time window to start the plot. Default: 0 (first window).\n",
    "        {RF_name}: Boolean; if False (default), the original rotational frame (RF1) is used. If True, then the\n",
    "        current self.rotFrame is used.\n",
    "        {instances}: Integer; number of instances to be plotted. Default: 5.\n",
    "        {savefig}: String that allows to save the figure in .png format by default.\n",
    "        {save_format}: Choose the saving format, 'png' by default, don't include the dot.   \n",
    "        \"\"\"\n",
    "        # Prepare data:\n",
    "        if stride_pp is None:\n",
    "            stride_pp = max(1,round(self.pp*0.8))\n",
    "        pp_i, pp_f = start_wdw, start_wdw+stride_pp*instances # Boundary indexes\n",
    "        t_data = self.time_wdw[pp_i:pp_f:stride_pp] # [s]\n",
    "        z_data = self.z_labels[pp_i:pp_f:stride_pp] # [m]\n",
    "        Bx_data = self.Bx_wdw_RFX[pp_i:pp_f:stride_pp] # [nT]\n",
    "        By_data = self.By_wdw_RFX[pp_i:pp_f:stride_pp] # [nT]\n",
    "        Bz_data = self.Bz_wdw_RFX[pp_i:pp_f:stride_pp] # [nT]\n",
    "        RF_title = self.rotFrame[2]\n",
    "        # Plot figure:\n",
    "        colors = plt.cm.viridis(np.linspace(0, 1, instances))\n",
    "        fig, (ax_Bz, ax_By, ax_Bx, ax_z) = plt.subplots(4,1,figsize=(6,4))\n",
    "        # Time windows:\n",
    "        for i in range(instances):\n",
    "            ax_Bx.scatter(t_data[i],Bx_data[i],color=colors[i],alpha=0.8)\n",
    "            ax_By.scatter(t_data[i],By_data[i],color=colors[i],alpha=0.8)\n",
    "            ax_Bz.scatter(t_data[i],Bz_data[i],color=colors[i],alpha=0.8)\n",
    "            ax_z.scatter(t_data[i][-1],z_data[i],color=colors[i],alpha=0.8)\n",
    "        # Floor references:\n",
    "        label = 'Levels'\n",
    "        for z in np.append(0,4.1+np.arange(0,3.7*6+0.1,3.7)):\n",
    "            ax_z.axhline(z,ls='--',alpha=0.2,label=label)\n",
    "            label = None # Prevent further labeling\n",
    "        # Configuration:\n",
    "        ax_z.legend(), ax_z.set(xlabel='Time [s]',ylabel='z labels [m]')\n",
    "        ax_z.set_ylim([np.min(z_data)-1,np.max(z_data)+1]) # z limits [m]\n",
    "        ax_z.spines['right'].set_visible(False), ax_z.spines['top'].set_visible(False)\n",
    "        axes_B = [ax_Bx, ax_By, ax_Bz]; labels_B = ['Bx','By','Bz']\n",
    "        for i in range(3):\n",
    "            axes_B[i].set(ylabel=f'{labels_B[i]} [nT]')\n",
    "            axes_B[i].set_xticks([])\n",
    "            for spin in ['right','bottom','top']:\n",
    "                axes_B[i].spines[spin].set_visible(False)\n",
    "        for ax in axes_B+[ax_z]:\n",
    "            ax.set_xlim([t_data[0][0]-1,t_data[-1][-1]+1])\n",
    "        plt.suptitle(f'{self.name} ; Rotational Frame {RF_title}')\n",
    "        fig.tight_layout()\n",
    "        if savefig:\n",
    "            save_file(savefig,save_format=save_format)\n",
    "        plt.show()\n",
    "\n",
    "    def matrix_format(self,mag_comps):\n",
    "        \"\"\"\n",
    "        Returns a Numpy array with the magnetic signals in the current rotated frame RFX, in a matrix format\n",
    "        suitable for Machine Learning models.\n",
    "        \n",
    "        --- Inputs ---\n",
    "        \n",
    "        {mag_comps}: List; each element is a string representing the magnetic components that will be used, must choose\n",
    "        from options \"Bx\", \"By\", \"Bz\" and/or \"B\".\n",
    "        \n",
    "        --- Outputs ---\n",
    "        \n",
    "        Numpy array with shape [samples,time_wdw_pp,channels], in [nT] units, each channel is a magnetic component.\n",
    "        The order of magnetic components is always Bx, By, Bz, B (ignoring not required components).\n",
    "        \"\"\"\n",
    "        mag_data = [] # Initiate list with all magnetic numpy arrays\n",
    "        if \"Bx\" in mag_comps:\n",
    "            mag_data.append(self.Bx_wdw_RFX)\n",
    "        if \"By\" in mag_comps:\n",
    "            mag_data.append(self.By_wdw_RFX)\n",
    "        if \"Bz\" in mag_comps:\n",
    "            mag_data.append(self.Bz_wdw_RFX)\n",
    "        if \"B\" in mag_comps:\n",
    "            mag_data.append(self.B_wdw)\n",
    "            \n",
    "        return np.stack(mag_data,axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1951ec3-8885-4d0b-b5f4-3e2cf2f00fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_and_reduce_TimeWdw(time_wdw,p_train):\n",
    "    \"\"\"\n",
    "    Copy the basic attributes of a Time_Wdw object, except for its time windows if any,\n",
    "    reduce the original data to a fraction (cutting off from the last chronological data)\n",
    "    and returns a new Time_Wdw object. Ignores any rotated data.\n",
    "    {time_wdw}: Time Window object; information must be already stored, except for time\n",
    "    windows (which will not be copied).\n",
    "    {p_train}: Float; fraction between 0 and 1 that sets how much of the original training\n",
    "    dataset is going to be preserved.\n",
    "    \"\"\"\n",
    "    # Initiate object and copy attributes:\n",
    "    new_time_wdw = Time_Wdw(time_wdw.pp, time_wdw.name, gr_tr=time_wdw.gr_tr)\n",
    "    N_max = int(len(time_wdw.time)*p_train) # Last point to be preserved\n",
    "    new_time_wdw.time = time_wdw.time[:N_max] # [s]\n",
    "    new_time_wdw.Bx_RF1 = time_wdw.Bx_RF1[:N_max] # [nT]\n",
    "    new_time_wdw.By_RF1 = time_wdw.By_RF1[:N_max] # [nT]\n",
    "    new_time_wdw.Bz_RF1 = time_wdw.Bz_RF1[:N_max] # [nT]\n",
    "    new_time_wdw.B_RF1 = time_wdw.B_RF1[:N_max] # [nT]\n",
    "    new_time_wdw.z = time_wdw.z[:N_max] # Z-position [m]\n",
    "    new_time_wdw.norm_value = time_wdw.norm_value # [nT]\n",
    "\n",
    "    return new_time_wdw     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ff0ee7c-08d7-4d74-89f0-830391ccd935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_TW_segments(t_wdws):\n",
    "    \"\"\"\n",
    "    Summarizes the segment distribution for time windows.\n",
    "    --- Inputs ---\n",
    "    {t_wdws}. Type: List, each element is a Time_Wdw object. \n",
    "    Definition: List containing all time windows associated to different segments.\n",
    "    All Time Windows must have the same number of points.\n",
    "    \"\"\"\n",
    "    N = 0 # Initiate total number of points for the t_wdws collection\n",
    "    for wdw in t_wdws:\n",
    "        print(f'{wdw.name}: {len(wdw.z)} points, {int(len(wdw.z)/600)} min')\n",
    "        N += len(wdw.z)\n",
    "    print(f'Total points/time: {N} / {np.round(N/36000,2)} hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ddaa5e3-bdef-4355-ae0a-7b9589e2b9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-18 16:40:47.247972: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-18 16:40:47.273591: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-18 16:40:47.273625: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-18 16:40:47.274471: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-18 16:40:47.278815: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-18 16:40:47.780781: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import InputLayer,Reshape,Dense,Dropout,Conv1D,MaxPooling1D,Flatten,GlobalAveragePooling1D\n",
    "from keras.backend import count_params# as K\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86a03cc4-6ce2-48ab-acef-9b827d72b5a5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [],
   "source": [
    "class ML_Model:\n",
    "    \"\"\"\n",
    "    The Machine Learning Model object <ML_Model> contains an supervised artificial intelligence model\n",
    "    that can be trained and tested with <Time_Wdw> objects. It predicts the z-position of the elevator\n",
    "    based on magnetic field signals. It can work in arbitrary rotational frames.\n",
    "\n",
    "    --- Attributes ---\n",
    "    \n",
    "    {self.hyps}: Dictionary; it contains all the hyper-parameters information to build the Keras model, \n",
    "    with the following keys and value examples:\n",
    "        * \"Time_Window_pp\": 20\n",
    "        * \"Magnetic_Components\": [\"Bx\",\"Bz\"] # Order does not matter\n",
    "        * \"Loss_Function\": \"MAE\"\n",
    "        * \"Last_Activation_Function\": 'linear'\n",
    "        * \"Batch_Size\": 128,\n",
    "        * \"Epochs\": 50\n",
    "        * \"Training_p_val\": 0.2 # Validation dataset fraction\n",
    "        * \"Early_Stop_Monitor\": \"val_loss\" # Criterium for early stopping during training.\n",
    "        * \"Earlt_Stop_Min_Delta\": 0 # Minimum improvement to prevent early stopping.\n",
    "        * \"Early_Stop_Patience\": 10 # Epochs during which the early stopping happens if no\n",
    "        improvement is registered.\n",
    "        * \"Early_Stop_Start_From_Epoch\": 20 # First epochs in which early stopping can't occur.\n",
    "        * \"Early_Stop_Restore_Best_Weights\": True # Allows to restore best weights when the\n",
    "        training is early stopped.\n",
    "        * \"z_thres\": 1 # z-value threshold for accuracy, in [m]\n",
    "        * \"Activation_Function\": 'tanh'\n",
    "        * \"Optimizer\": 'adam'\n",
    "        * \"Learning_Rate\": 0.0003\n",
    "        * \"RF\": [[np.array([0.41,0.75,0.52]),90,'RF2']] # List with rotational frames, each element is a list with\n",
    "        the format [Numpy array,String,Numeric]; meaning [rotation axis in (x,y,z) format, rotation angle in degree,\n",
    "        RF name]. If RF name is 'RF1', then the data in kept in the original frame (defined as \"RF1\").\n",
    "        * \"Convolutional_Network\": True # Allow to use Convolutional Layers before the Dense layers\n",
    "        * \"Conv_Layers\": [[64,5],[128,5]] # List with Conv. layers, in order, in the format [filters,kernel size]\n",
    "        * \"Pool_Layers\": [None,None] # List with pooling layers, in order, each element is the size (None=ignore layer)\n",
    "        * \"Flatten_Average\": If True, just flattens the input data. If False, makes a global averaging for the many Conv filters.\n",
    "        * \"Dens_Layers\": [1000,500] # List with dense layers, in order, each element is the number of neurons\n",
    "        * \"Dropout_Fraction\": 0.2 # Fraction for dropout layers after each dense layer (0=ignore layer)\n",
    "        * \"Model_Name\": \"S1_Conv_5_5\" # Usually contains the Stage and architecture information\n",
    "        * \"Full_Name\": \"S1_Conv_5_5_wdw2s_Bx_By_\" # Contains all the information\n",
    "        * \"Train_Segms\": \"segm1segm3\" # Specifies the segments used in training.\n",
    "        * \"Test_Segms\": \"segm1segm3\" # Specifies the segments used in testing.\n",
    "        * \"p_train\": 1 # Float between 0 and 1; fraction of the training dataset that is going\n",
    "        to be used. If 1: entire training dataset.\n",
    "        * \"seed\": 0 # Random initialization seed.\n",
    "        * \"N_augm\": 1 # Number of times the original training dataset will be augmented.\n",
    "        * \"noise\": [1,1,1] # List comprised of 3 float numbers; noise intensity for data\n",
    "        augmentation in the [Bx,By,Bz] components, in [nT] units. Only relevant if N_augm>0.\n",
    "    {self.model}: Keras object; Machine Learning model.\n",
    "    {self.seed}: Integer; seed used in weights initialization when building the model.\n",
    "    \"\"\"\n",
    "    def __init__(self, full_hyp, seed=0, load_model=None):\n",
    "        \"\"\"\n",
    "        --- Inputs ---\n",
    "        {full_hyp}: Dictionary with hyperparameters information.\n",
    "        {load_model}: None (default) or Keras object. If None, starts a new model. Else, load a previous model.\n",
    "        {seed}: Integer; seed for weight initialization. Default: 0.\n",
    "        \"\"\"\n",
    "        self.hyps = full_hyp # Incorporate hyper-parameters information\n",
    "        self.seed = seed # Record seed\n",
    "        # Start building model:\n",
    "        if load_model is not None:\n",
    "            self.model = tf.keras.models.load_model(load_model)\n",
    "        else:\n",
    "            self.model = Sequential() # Initiate Keras object\n",
    "            self.model.add(InputLayer(input_shape=(self.hyps[\"Time_Window_pp\"],\n",
    "                                                   len(self.hyps[\"Magnetic_Components\"])))) # First (input) layer\n",
    "            # Add Convolutional, Pooling and Flattening layers (if any):\n",
    "            if self.hyps[\"Convolutional_Network\"]:\n",
    "                for i in range(len(self.hyps[\"Conv_Layers\"])):\n",
    "                    self.model.add(Conv1D(\n",
    "                        filters=self.hyps[\"Conv_Layers\"][i][0],\n",
    "                        kernel_size=self.hyps[\"Conv_Layers\"][i][1],\n",
    "                        activation=self.hyps[\"Activation_Function\"],\n",
    "                        kernel_initializer=tf.keras.initializers.GlorotUniform(seed=self.seed),\n",
    "                        kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)\n",
    "                    ))\n",
    "                    if self.hyps[\"Pool_Layers\"][i] is not None:\n",
    "                        self.model.add(MaxPooling1D(pool_size=self.hyps[\"Pool_Layers\"][i]))\n",
    "                self.model.add(Flatten()) if self.hyps[\"Flatten_Average\"] else self.model.add(GlobalAveragePooling1D()) \n",
    "            else:\n",
    "                self.model.add(Flatten())\n",
    "            # Add Dense layers (and Dropout, if any):\n",
    "            for i in range(len(self.hyps[\"Dens_Layers\"])):\n",
    "                self.model.add(Dense(\n",
    "                    self.hyps[\"Dens_Layers\"][i],\n",
    "                    activation=self.hyps[\"Activation_Function\"],\n",
    "                    kernel_initializer='random_normal'))\n",
    "                if self.hyps[\"Dropout_Fraction\"]:\n",
    "                    self.model.add(Dropout(self.hyps[\"Dropout_Fraction\"]))\n",
    "            # Last layers:\n",
    "            self.model.add(Dense(1, activation=self.hyps[\"Last_Activation_Function\"],\n",
    "                                kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)\n",
    "                                ))\n",
    "            # Compile model:\n",
    "            self.model.compile(\n",
    "                loss=self.hyps[\"Loss_Function\"],\n",
    "                optimizer=self.hyps[\"Optimizer\"],\n",
    "            )\n",
    "    \n",
    "    def info(self):\n",
    "        \"\"\"\n",
    "        Prints in screen information about the ML model.\n",
    "        \"\"\"\n",
    "        print('-'*30)\n",
    "        print('Full name:',self.hyps[\"Full_Name\"])\n",
    "        print(\"Time windows' points:\",self.hyps[\"Time_Window_pp\"])\n",
    "        print(\"Input magnetic components:\",self.hyps[\"Magnetic_Components\"])\n",
    "        print(\"Model's trainable parameters:\",np.sum([count_params(w) for w in self.model.trainable_weights]))\n",
    "        print('-'*30)\n",
    "    \n",
    "    def train_model(self,time_wdws,RF_info,savefigs_path=None,save_format='png',\n",
    "                    exp_model_path=None):\n",
    "        \"\"\"\n",
    "        Trains the ML model based on provided <Time_Wdw> objects and specified rotational frame. Data is randomly\n",
    "        split between training and validation datasets.\n",
    "        \n",
    "        --- Inputs ---\n",
    "        \n",
    "        {time_wdws}: List; each element is a <Time_Wdw> object.\n",
    "        {RF_info}: List; each element is a rotational frame, a list with the format [Numpy array,Numeric,String];\n",
    "        meaning [rotation axis in (x,y,z) format, rotation angle in degree, RF name]. If RF[2]='RF1', then the\n",
    "        data is kept in the original frame.\n",
    "        {savefigs_path}: String; if specified, saves the training figures in .png format by default.\n",
    "        {save_format}: String; Choose the saving format, 'png' by default, don't include the dot.\n",
    "        {exp_model_path}: String; if specified, exports the ML model.\n",
    "        \n",
    "        --- Outputs ---\n",
    "        \n",
    "        {results}: Dictionary; contains information about the model and its results.\n",
    "        \"\"\"\n",
    "        # Prepare data according to magnetic components and rotational frame:\n",
    "        mag_data, z_data = [], [] # Initiate predictors and targets \n",
    "        for time_wdw in time_wdws:\n",
    "            time_wdw.rotate_frame(RF_info)\n",
    "            mag_data.append(time_wdw.matrix_format(self.hyps[\"Magnetic_Components\"])) # Array format [samples,wdw_pp,channels], units [nT]\n",
    "            z_data.append(time_wdw.z_labels) # z-position labels, units [m]\n",
    "        all_mag_data = np.concatenate(mag_data,axis=0) # Concatenate all arrays, units [nT]\n",
    "        all_z_data = np.concatenate(z_data,axis=0) # Concatenate all arrays, units [m]\n",
    "        # Normalize magnetic data:\n",
    "        all_mag_data /= time_wdws[0].norm_value # Adimensional units\n",
    "        # Split training/validating datasets:\n",
    "        msk = np.random.rand(all_mag_data.shape[0]) < 1-self.hyps[\"Training_p_val\"] # Mask for training indexes\n",
    "        X_train, Y_train = all_mag_data[msk], all_z_data[msk] # Training predictors and targets\n",
    "        X_val, Y_val = all_mag_data[~msk], all_z_data[~msk] # Validating predictors and targets\n",
    "        # Prepare callbacks:\n",
    "        early_stop = keras.callbacks.EarlyStopping(monitor=self.hyps[\"Early_Stop_Monitor\"],\n",
    "                                                   min_delta=self.hyps[\"Early_Stop_Min_Delta\"],\n",
    "                                                   mode='min',\n",
    "                                                   patience=self.hyps[\"Early_Stop_Patience\"],\n",
    "                                                   start_from_epoch=self.hyps[\"Early_Stop_Start_From_Epoch\"],\n",
    "                                                   restore_best_weights=self.hyps[\"Early_Stop_Restore_Best_Weights\"],\n",
    "                                                   verbose=1\n",
    "                                                  )\n",
    "        # Train the model:\n",
    "        with tf.device('/GPU:0'):\n",
    "            history = self.model.fit(X_train,Y_train,\n",
    "                                     validation_data=(X_val, Y_val),\n",
    "                                     epochs=self.hyps[\"Epochs\"],\n",
    "                                     callbacks=[plot_losses,early_stop],\n",
    "                                     batch_size=self.hyps[\"Batch_Size\"],\n",
    "                                     verbose=1)\n",
    "        # Save the training figure:\n",
    "        history_frame = pd.DataFrame(history.history) # Generate training dataframe\n",
    "        epochs = range(1,len(history_frame)+1) # (Range) Effective epochs\n",
    "        if savefigs_path is not None:\n",
    "            fig_name = f'Training_{self.hyps[\"Full_Name\"]}'\n",
    "            fig, ax = plt.subplots(figsize=(6,3))\n",
    "            ax.plot(epochs,history_frame['val_loss'],'-s', label=\"val_loss\", color='gray', alpha=0.8)\n",
    "            ax.plot(epochs,history_frame['loss'],'-o', label=\"loss\", color='brown', alpha=0.8)\n",
    "            # ax.axhline(2,ls='--',color='orange'), \n",
    "            # ax.axhline(1,ls='--',color='g')\n",
    "            ax.set(xlabel='Epochs',ylabel='Loss (MAE) [m]')\n",
    "            ax.legend()\n",
    "            fig.tight_layout()\n",
    "            save_file(savefigs_path+fig_name,save_format=save_format)\n",
    "            plt.close(fig)\n",
    "\n",
    "        # Predictions on validation dataset:\n",
    "        z_val_pred = np.squeeze(self.model.predict(X_val,verbose=1)) # Get the predictions [m]\n",
    "        AE_val = np.transpose(np.abs(Y_val-z_val_pred)) # Array with absolute errors [m]\n",
    "        # Calculate accuracy according to different threshold:\n",
    "        acc_z = sum(AE_val<self.hyps[\"z_thres\"])/len(AE_val)*100 # [%]\n",
    "        print('-'*30)\n",
    "        print(f'VALIDATING; Accuracy using {self.hyps[\"z_thres\"]}m threshold: {np.round(acc_z,1)}%')\n",
    "        print('-'*30)\n",
    "        \n",
    "        # Save histogram-results figure (validation dataset):\n",
    "        # if savefigs_path is not None:\n",
    "        #     weights = np.ones_like(AE_val) / len(AE_val)\n",
    "        #     fig_name = f'Preds_Hist_Val_{self.hyps[\"Full_Name\"]}_{RF_info[2]}_seed{self.seed}'\n",
    "        #     fig_name += f'_pp{self.hyps[\"Time_Window_pp\"]}'\n",
    "        #     fig, ax = plt.subplots(figsize=(6,3))\n",
    "        #     ax.hist(AE_val, weights=weights, bins=np.arange(0, max(AE_val) + 0.25, 0.25),\n",
    "        #             color='gray', alpha=0.8, label = \"Counts\")\n",
    "        #     ax.hist(AE_val, weights=weights, cumulative=True, bins=np.arange(0, max(AE_val) + 0.25, 0.25),\n",
    "        #             color='green', alpha=0.2, label = \"Cumulative\")\n",
    "        #     ax.axvline(2,ls='--',color='orange', label=\"Minimum AE\")\n",
    "        #     ax.axvline(1,ls='--',color='g', label=\"Optimal AE\")\n",
    "        #     ax.legend()\n",
    "        #     ax.set(xlabel='Absolute Error [m]',ylabel='Prob. Density')\n",
    "        #     fig.tight_layout()\n",
    "        #     save_file(savefigs_path+f'Preds_Hist_Val_{self.hyps[\"Full_Name\"]}',\n",
    "        #               save_format=save_format)\n",
    "        #     plt.close(fig)\n",
    "            \n",
    "        # Export the ML model:\n",
    "        if exp_model_path is not None:\n",
    "            self.model.save(exp_model_path+self.hyps[\"Full_Name\"]+'.keras')\n",
    "      \n",
    "        # Generate dictionary with results:\n",
    "        res_train = { # First basic parameters:\n",
    "                \"Full_Name\": self.hyps[\"Full_Name\"],\n",
    "                \"Wdw_pp\": self.hyps[\"Time_Window_pp\"],\n",
    "                \"Mag_Comps\": \"\".join(self.hyps[\"Magnetic_Components\"]),\n",
    "                \"RF\": RF_info[2],\n",
    "                \"Seed\": self.seed,\n",
    "                \"Train_Segms\": self.hyps[\"Train_Segms\"],\n",
    "                \"Batch\": self.hyps[\"Batch_Size\"],\n",
    "                \"Epochs\": epochs[-1],\n",
    "                \"p_val\": self.hyps[\"Training_p_val\"],\n",
    "                \"Activ_func\": self.hyps[\"Activation_Function\"],\n",
    "                \"Optimizer\": self.hyps[\"Optimizer\"],\n",
    "                \"Learn_rate\": self.hyps[\"Learning_Rate\"],\n",
    "                \"Model_Name\": self.hyps[\"Model_Name\"],\n",
    "                \"Best_MAE_val\": min(history_frame['val_loss']), # [m]\n",
    "                \"Best_MAE_train\": min(history_frame['loss']), # [m]\n",
    "                \"z_thres\": self.hyps[\"z_thres\"], # [m]\n",
    "                \"Acc_Val_z\": acc_z, # [%]\n",
    "                \"Trainable_pars\": np.sum([count_params(w) for w in self.model.trainable_weights])\n",
    "                }\n",
    "        # Then optional parameters:\n",
    "        for par in ['p_train','N_augm','noise']:\n",
    "            if par in self.hyps:\n",
    "                if par=='noise':\n",
    "                    res_train['Bx_noise'] = self.hyps[par][0]\n",
    "                    res_train['By_noise'] = self.hyps[par][1]\n",
    "                    res_train['Bz_noise'] = self.hyps[par][2]\n",
    "                else:\n",
    "                    res_train[par] = self.hyps[par]\n",
    "        \n",
    "        return res_train\n",
    "    \n",
    "    def test_model(self,time_wdws,RF_info,return_preds=False,savefigs_path=None,save_format='png'):\n",
    "        \"\"\"\n",
    "        Tests the ML model (already trained) on provided <Time_Wdw> objects and specified\n",
    "        rotational frame. Returns the performance results and, if requested, the ground truth\n",
    "        and predicted arrays.\n",
    "        \n",
    "        --- Inputs ---\n",
    "        \n",
    "        {time_wdws}: List; each element is a <Time_Wdw> object.\n",
    "        {RF_info}: List; each element is a rotational frame, a list with the format [Numpy array,Numeric,String];\n",
    "        meaning [rotation axis in (x,y,z) format, rotation angle in degree, RF name]. If RF[2]='RF1', then the\n",
    "        data is kept in the original frame.\n",
    "        {return_preds}: Boolean; if True, returns the ground truth and predicted arrays. Default: False.\n",
    "        {savefigs_path}: String; if specified, saves the training figures in .png format by default.\n",
    "        {save_format}: String; Choose the saving format, 'png' by default, don't include the dot.\n",
    "        \n",
    "        --- Outputs ---\n",
    "        \n",
    "        {results}: Dictionary; contains information about the model and its results.\n",
    "        Optional:\n",
    "        {t_data}: List; each element is a Numpy array representing the time, correlated with\n",
    "        z-position, for a single segment. Units [s].\n",
    "        {z_data}: List; each element is a Numpy array representing the ground truth for z-position\n",
    "        for a single segment. Units [m].\n",
    "        {z_preds}: List; each element is a Numpy array representing the predictions for z-position\n",
    "        for a single segment. Units [m].\n",
    "        \"\"\"\n",
    "        # Prepare data according to magnetic components and rotational frame:\n",
    "        segms = [time_wdw.name for time_wdw in time_wdws]\n",
    "        self.hyps[\"Test_Segms\"] = \"\".join(segms)\n",
    "        mag_data, z_data, t_data = [], [], [] # Initiate predictors, targets and time\n",
    "        for time_wdw in time_wdws:\n",
    "            time_wdw.rotate_frame(RF_info)\n",
    "            mag_data.append(time_wdw.matrix_format(self.hyps[\"Magnetic_Components\"])) # Array format [samples,wdw_pp,channels], units [nT]\n",
    "            z_data.append(time_wdw.z_labels) # z-position labels, units [m]\n",
    "            t_data.append(time_wdw.time[time_wdw.pp:]) # Time, units [s]\n",
    "        all_mag_data = np.concatenate(mag_data,axis=0) # Concatenate all arrays, units [nT]\n",
    "        all_z_data = np.concatenate(z_data,axis=0) # Concatenate all arrays, units [m]\n",
    "        all_t_data = np.concatenate(t_data,axis=0) # Concatenate all arrays, units [s]\n",
    "        # Normalize magnetic data:\n",
    "        all_mag_data /= time_wdws[0].norm_value # Adimensional units\n",
    "        for vec in mag_data:\n",
    "            vec /= time_wdws[0].norm_value # Adimensional units\n",
    "        \n",
    "        # Obtain predictions and calculate performance metrics for ALL data:\n",
    "        z_pred = np.squeeze(self.model.predict(all_mag_data,verbose=1)) # Get the predictions [m]\n",
    "        AE_test = np.transpose(np.abs(all_z_data-z_pred)) # Array with absolute errors [m]\n",
    "        # Calculate accuracy according to different threshold:\n",
    "        acc_z = sum(AE_test<self.hyps[\"z_thres\"])/len(AE_test)*100 # [%]\n",
    "        print('-'*30)\n",
    "        print(f'TESTING; Accuracy using {self.hyps[\"z_thres\"]}m threshold: {np.round(acc_z,1)}%')\n",
    "        print('-'*30)\n",
    "        # Obtain predictions for each segment:\n",
    "        z_preds = [np.squeeze(self.model.predict(mag_data[i],verbose=2)) for i in range(len(mag_data))] # [m]\n",
    "\n",
    "        # Save the predictions figure:\n",
    "        if savefigs_path is not None:\n",
    "            for i in range(len(t_data)):\n",
    "                fig_name = f'Testing_{self.hyps[\"Full_Name\"]}_{time_wdws[i].name}'\n",
    "                fig, ax = plt.subplots(figsize=(8,3))\n",
    "                ax.plot(t_data[i],z_data[i],'--',color='teal',lw=0.5,label='Actual',alpha=0.8)\n",
    "                ax.plot(t_data[i],z_preds[i],'-r',lw=0.5,label='Predictions',alpha=0.8)\n",
    "                for z in np.append(0,4.1+np.arange(0,3.7*6+0.1,3.7)):\n",
    "                    ax.axhline(z,ls='-',lw=0.5,alpha=0.2)         \n",
    "                ax.set(xlabel='Time [s]',ylabel='z-pos [m]')\n",
    "                ax.legend()\n",
    "                fig.tight_layout()\n",
    "                save_file(savefigs_path+fig_name,save_format=save_format)\n",
    "                plt.show()\n",
    "\n",
    "        # Save histogram-results figure (testing dataset):\n",
    "        # if savefigs_path is not None:\n",
    "        #     weights = np.ones_like(AE_test) / len(AE_test)\n",
    "        #     fig_name = f'Preds_Hist_Test_{self.hyps[\"Full_Name\"]}_{RF_info[2]}_seed{self.seed}'\n",
    "        #     fig_name += f'_pp{self.hyps[\"Time_Window_pp\"]}'\n",
    "        #     fig, ax = plt.subplots(figsize=(6,3))\n",
    "        #     ax.hist(AE_test, weights=weights, bins=np.arange(0, max(AE_test) + 0.25, 0.25),\n",
    "        #             color='gray', alpha=0.8, label = \"Counts\")\n",
    "        #     ax.hist(AE_test, weights=weights, cumulative=True, bins=np.arange(0, max(AE_test) + 0.25, 0.25),\n",
    "        #             color='green', alpha=0.2, label = \"Cumulative\")\n",
    "        #     ax.axvline(2,ls='--',color='orange', label=\"Minimum AE\")\n",
    "        #     ax.axvline(1,ls='--',color='g', label=\"Optimal AE\")\n",
    "        #     ax.legend()\n",
    "        #     ax.set(xlabel='Absolute Error [m]',ylabel='Prob. Density')\n",
    "        #     fig.tight_layout()\n",
    "        #     save_file(savefigs_path+f'Preds_Hist_Test_{self.hyps[\"Full_Name\"]}',\n",
    "        #               save_format=save_format)\n",
    "        #     plt.show()\n",
    "\n",
    "        res_test = {\n",
    "            \"Test_Segms\": self.hyps[\"Test_Segms\"],\n",
    "            \"MAE_test\": AE_test.mean(),\n",
    "            \"Acc_Test_z\": acc_z,\n",
    "        }\n",
    "        if return_preds:\n",
    "            return res_test, t_data, z_data, z_preds\n",
    "        else:\n",
    "            return res_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f744c98b-4248-40f9-bf14-741a4600d989",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "class PlotLosses(keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    This class will be used to plot live charts of the training process.\n",
    "    \"\"\"\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []        \n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):        \n",
    "        self.logs.append(logs)\n",
    "        self.x.append(self.i+1)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.i += 1\n",
    "        self.fig = plt.figure(figsize=(6,3))\n",
    "        clear_output(wait=True)\n",
    "        if not all(elem is None for elem in self.val_losses):\n",
    "            plt.plot(self.x, self.val_losses,'-s', label=\"val_loss\", color='gray', alpha=0.8)        \n",
    "        plt.plot(self.x, self.losses,'-o', label=\"loss\", color='brown', alpha=0.8)\n",
    "        # plt.axhline(1,ls='--',color='g')\n",
    "        plt.legend()\n",
    "        plt.xlabel(\"Epochs\"), plt.ylabel(\"Loss (MAE) [m]\")\n",
    "        #plt.yscale('log') \n",
    "        plt.show()\n",
    "        \n",
    "plot_losses = PlotLosses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66487aef-124f-48d2-88a3-4c9ea14ad8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_results(df_results,test_col,val_col,groupby=None):\n",
    "    \"\"\"\n",
    "    Plots the validating and testing results, to show overfitting or \n",
    "    underfitting. If requested, the plot will be replicated for different\n",
    "    grouping features.\n",
    "    --- Inputs ---\n",
    "    {df_results}: Type: Dataframe. It must have the columns {test_col}\n",
    "    and {val_col}.\n",
    "    {test_col}: String; name for testing results. Content must be in [%] units.\n",
    "    {val_col}: String; name for validating results. Content must be in [%] units.\n",
    "    {groupby}: List or None. If a list is provided, each element must be a\n",
    "    feature present in {df_results}. For each feature, a scoring plots will\n",
    "    be shown, grouped by that feature.\n",
    "    \"\"\"\n",
    "    if groupby is not None:\n",
    "        for feature in groupby:\n",
    "            group_name = df_results[feature].unique()\n",
    "            colors = plt.cm.viridis(np.linspace(0, 1,len(group_name)+1))\n",
    "            fig, ax = plt.subplots(figsize=(6,4))    \n",
    "            # Plot results:\n",
    "            for i, group in enumerate(group_name):\n",
    "                data = df_results[df_results[feature]==group]\n",
    "                ax.plot(data[test_col],data[val_col],\n",
    "                        markers[i%len(markers)],color=colors[i],\n",
    "                        alpha=0.7,label=group)\n",
    "            # Plot identity line:\n",
    "            xmin,xmax = ax.get_xlim()    \n",
    "            ID = np.linspace(xmin,xmax,3)\n",
    "            ax.plot(ID,ID,'--k')\n",
    "            ax.set(xlabel=\"Testing Accuracy [%]\",ylabel=\"Training Accuracy\")\n",
    "            ax.set_title(f'Results grouped by {feature}')\n",
    "            ax.legend(title=feature)\n",
    "            fig.tight_layout()\n",
    "            plt.show()\n",
    "    else:\n",
    "        fig, ax = plt.subplots(figsize=(6,4))    \n",
    "        # Plot results:\n",
    "        ax.scatter(df_results[test_col],df_results[val_col],\n",
    "                   color='orange',edgecolor='gray',alpha=0.6)\n",
    "        # Plot identity line:\n",
    "        xmin,xmax = ax.get_xlim()    \n",
    "        ID = np.linspace(xmin,xmax,3)\n",
    "        ax.plot(ID,ID,'--k')\n",
    "        ax.set(xlabel=\"Testing Accuracy [%]\",ylabel=\"Training Accuracy\")\n",
    "        ax.text(xmin,max(df_results[val_col])*0.95, \"Overfitting \", ha='left')\n",
    "        ax.text(xmax, ax.get_ylim()[0]*1.01, \"Underfitting \", ha='right')\n",
    "        ax.set_title('All results')\n",
    "        fig.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1c04ba5-fd8d-458c-a7fe-75e9704bee2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_stage1(B_comps_opts,arch_opts,seed_opts,RF_opts,\n",
    "                 t_wdws_train,t_wdws_test,savefigs_path=None,\n",
    "                 exp_model_path=None,results_path='./',\n",
    "                 check_rep_model=None,quick_timing_test=False):\n",
    "    \"\"\"\n",
    "    Training procedure for Stage 1, focusing on magnetic components. It trains many\n",
    "    ML models using different options for magnetic components, architectures, seeds\n",
    "    and rotational frames. It returns and exports a dataframe with the results.\n",
    "\n",
    "    --- Inputs ---\n",
    "\n",
    "    {B_comps_opts}: List; each element is a list in which the different magnetic\n",
    "    components are included as elements. Options: 'Bx', 'By', 'Bz', 'B'.\n",
    "    {arch_opts}: List; each element is a dictionary with the ML model hyper-parameters,\n",
    "    see {self.hyps} attribute for <ML_Model> object.\n",
    "    {seed_opts}: List; each element is an integer meaning a random initialization seed.\n",
    "    {RF_opts}: List; each element is a list with the format [Numpy array,Numeric,String];\n",
    "    meaning [rotation axis in (x,y,z) format, rotation angle in degree, RF name].\n",
    "    If RF[2]='RF1', then the data is kept in the original frame.\n",
    "    {t_wdws_train}: List; each element is a <Time_Wdw> object that will be used for\n",
    "    the training process.\n",
    "    {t_wdws_test}: List; each element is a <Time_Wdw> object that will be used for\n",
    "    the testing process.\n",
    "    {savefigs_path}: String; if specified, saves the training figures in .png format by default.\n",
    "    {save_format}: String; Choose the saving format, 'png' by default, don't include the dot.\n",
    "    {exp_model_path}: String; if specified, exports the ML model.\n",
    "    {results_path}: String; path for exporting results. Default: current directory.\n",
    "    {check_rep_model}: String or None; if provided, use a .csv file as a reference, same format\n",
    "    as the output of this function, to skip any already trained model. Default: None.\n",
    "    {quick_timing_test}: Boolean. If True, ONLY runs a dry test (no savings of any type) for 5 epochs\n",
    "    and estimate the total training times.\n",
    "\n",
    "    --- Outputs ---\n",
    "\n",
    "    {pd_results}: Pandas dataframe; information about the ML models' results.\n",
    "    \n",
    "    \"\"\"\n",
    "    # If provided, load the reference file:\n",
    "    if check_rep_model is not None:\n",
    "        pd_ref = pd.read_csv(check_rep_model)\n",
    "        trained_models = list(pd_ref[\"Full_Name\"]) # Extract the full names of trained ML models\n",
    "    else:\n",
    "        trained_models = []\n",
    "    # Initiate dataframe:\n",
    "    pd_results = pd.DataFrame(columns=['Full_Name','Wdw_pp','Mag_Comps','RF','Seed',\n",
    "                                       'Train_Segms','Test_Segms',\n",
    "                                       'Batch','Epochs','p_val','Activ_func','Optimizer',\n",
    "                                       'Learn_rate','Model_Name','Best_MAE_val',\n",
    "                                       'Best_MAE_train','MAE_test',\n",
    "                                       'z_thres','Acc_Val_z','Acc_Test_z'])\n",
    "    # Prepare time windows:\n",
    "    segms_train = [time_wdw.name for time_wdw in t_wdws_train] # List with training segments' names\n",
    "    segms_test = [time_wdw.name for time_wdw in t_wdws_test] # List with testing segments' names\n",
    "    for subset in [t_wdws_train,t_wdws_test]:\n",
    "        for t_wdw in subset: \n",
    "            t_wdw.window_data()\n",
    "\n",
    "    # Train all models:    \n",
    "    N_models = 0 # Initiatie auxiliar count\n",
    "    for B_comps in B_comps_opts: # Iterate over magnetic components\n",
    "        for arch in arch_opts: # Iterate over ML architectures\n",
    "            for RF in RF_opts: # Iterate over rotational frames\n",
    "                for seed in seed_opts: # Iterate over random initialization seeds\n",
    "                    # Prepare hyper-parameter options for model:\n",
    "                    full_hyp = arch.copy() # Initiate Full Hyper-parameters dictionary\n",
    "                    full_hyp[\"Magnetic_Components\"] = B_comps\n",
    "                    full_hyp[\"Full_Name\"] = arch[\"Model_Name\"]+'_'+'_'.join([b for b in B_comps])\n",
    "                    full_hyp[\"Full_Name\"] += f'_{RF[2]}_seed{seed}_{\"\".join(segms_train)}'\n",
    "                    # Train the model (if not trained yet):\n",
    "                    if full_hyp[\"Full_Name\"] not in trained_models:\n",
    "                        N_models += 1 # Update number of trainable models\n",
    "                        full_hyp[\"Train_Segms\"] = \"\".join(segms_train)\n",
    "                        full_hyp[\"Test_Segms\"] = \"\".join(segms_test)\n",
    "                        if not quick_timing_test:\n",
    "                            # Train the model:\n",
    "                            keras.backend.clear_session()\n",
    "                            ML_model = ML_Model(full_hyp,seed=seed)\n",
    "                            res_train = ML_model.train_model(t_wdws_train,RF,savefigs_path=savefigs_path,\n",
    "                                                             exp_model_path=exp_model_path)\n",
    "                            # Test the model:\n",
    "                            res_test = ML_model.test_model(t_wdws_test,RF,savefigs_path=savefigs_path)\n",
    "                            # Update results:\n",
    "                            results = dict(list(res_train.items())+list(res_test.items()))\n",
    "                            pd_results.loc[len(pd_results)] = results\n",
    "                            # Export .csv file (overwrites in everystep):\n",
    "                            name = f'AI_S1_{len(B_comps_opts)}magcomps_{len(seed_opts)}seeds'\n",
    "                            name += f'_{len(RF_opts)}RFs_wdw{t_wdws_train[0].pp}pp.csv'\n",
    "                            pd_results.to_csv(results_path+name, index=False)\n",
    "    if quick_timing_test:\n",
    "        print('-'*10,' QUICK TIMING TEST MODE ','-'*10)\n",
    "        print('Running dry test for 5 epochs...')\n",
    "        time.sleep(1)\n",
    "        # Only train last ML model:\n",
    "        full_hyp['Epochs'] = 5\n",
    "        start = time.time()\n",
    "        keras.backend.clear_session()\n",
    "        ML_model = ML_Model(full_hyp,seed=seed)\n",
    "        _ = ML_model.train_model(t_wdws_train,RF)\n",
    "        _ = ML_model.test_model(t_wdws_test,RF)\n",
    "        end = time.time()\n",
    "        elapsed_time = end - start # [s]\n",
    "        single_model_est_time = elapsed_time/5*arch['Epochs']/60 # [min]\n",
    "        # Print estimated times:\n",
    "        print('\\n','-'*40,'\\n')\n",
    "        print(f'Trainable models in this training session:',N_models)\n",
    "        print(f'Estimated training time per model: {np.round(single_model_est_time,1)} min')\n",
    "        print(f'Estimated total time: {np.round(single_model_est_time*N_models/60,1)} hours')\n",
    "        print('\\n','-'*10,' IMPORTANT ','-'*10,'\\n')\n",
    "        print('If you want to train all models, select quick_timing_test=False')\n",
    "            \n",
    "    return pd_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8152a6be-01b2-40b5-a608-360eb78e68f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_stage2(pp_opts,arch_opts,seed_opts,RF_opts,\n",
    "                 t_wdws_train,t_wdws_test,savefigs_path=None,\n",
    "                 exp_model_path=None,results_path='./',\n",
    "                 check_rep_model=None,quick_timing_test=False):\n",
    "    \"\"\"\n",
    "    Training procedure for Stage 2, focusing on time windows' length. It trains many\n",
    "    ML models using different options for magnetic components, architectures, seeds\n",
    "    and rotational frames. It returns and exports a dataframe with the results.\n",
    "\n",
    "    --- Inputs ---\n",
    "\n",
    "    {pp_opts}: List; each element is an integer meaning the number of points for each\n",
    "    time window.\n",
    "    {arch_opts}: List; each element is a dictionary with the ML model hyper-parameters,\n",
    "    see {self.hyps} attribute for <ML_Model> object.\n",
    "    {seed_opts}: List; each element is an integer meaning a random initialization seed.\n",
    "    {RF_opts}: List; each element is a list with the format [Numpy array,Numeric,String];\n",
    "    meaning [rotation axis in (x,y,z) format, rotation angle in degree, RF name].\n",
    "    If RF[2]='RF1', then the data is kept in the original frame.\n",
    "    {t_wdws_train}: List; each element is a <Time_Wdw> object that will be used for\n",
    "    the training process. The number of points for each time window doesn't matter.\n",
    "    {t_wdws_test}: List; each element is a <Time_Wdw> object that will be used for\n",
    "    the testing process. The number of points for each time window doesn't matter.\n",
    "    {savefigs_path}: String; if specified, saves the training figures in .png format by default.\n",
    "    {save_format}: String; Choose the saving format, 'png' by default, don't include the dot.\n",
    "    {exp_model_path}: String; if specified, exports the ML model.\n",
    "    {results_path}: String; path for exporting results. Default: current directory.\n",
    "    {check_rep_model}: String or None; if provided, use a .csv file as a reference, same format\n",
    "    as the output of this function, to skip any already trained model. Default: None.    \n",
    "    {quick_timing_test}: Boolean. If True, ONLY runs a dry test (no savings of any type) for 5 epochs\n",
    "    and estimate the total training times.\n",
    "    \n",
    "    --- Outputs ---\n",
    "\n",
    "    {pd_results}: Pandas dataframe; information about the ML models' results.\n",
    "    \n",
    "    \"\"\"\n",
    "    # If provided, load the reference file:\n",
    "    if check_rep_model is not None:\n",
    "        pd_ref = pd.read_csv(check_rep_model)\n",
    "        trained_models = list(pd_ref[\"Full_Name\"]) # Extract the full names of trained ML models\n",
    "    else:\n",
    "        trained_models = []\n",
    "    # Initiate dataframe:\n",
    "    pd_results = pd.DataFrame(columns=['Full_Name','Wdw_pp','Mag_Comps','RF','Seed',\n",
    "                                       'Train_Segms','Test_Segms',\n",
    "                                       'Batch','Epochs','p_val','Activ_func','Optimizer',\n",
    "                                       'Learn_rate','Model_Name','Best_MAE_val',\n",
    "                                       'Best_MAE_train','MAE_test',\n",
    "                                       'z_thres','Acc_Val_z','Acc_Test_z'])\n",
    "    # First, get the segments' names (time windows):\n",
    "    segms_train = [time_wdw.name for time_wdw in t_wdws_train] # List with training segments' names\n",
    "    segms_test = [time_wdw.name for time_wdw in t_wdws_test] # List with testing segments' names\n",
    "\n",
    "    # Train all models:\n",
    "    N_models = 0 # Initiatie auxiliar count\n",
    "    for pp in pp_opts: # Iterate over number of points for time windows\n",
    "        # Iterate over ML architectures\n",
    "        for arch in arch_opts:\n",
    "            # Only train architectures which are valid for the current number of points:\n",
    "            if arch[\"Convolutional_Network\"]:\n",
    "                if np.sum([filt_kern[1] for filt_kern in arch[\"Conv_Layers\"]])>pp:\n",
    "                    continue # Skip this training\n",
    "            for RF in RF_opts: # Iterate over rotational frames\n",
    "                for seed in seed_opts: # Iterate over random initialization seeds\n",
    "                    # Prepare hyper-parameter options for model:\n",
    "                    full_hyp = arch.copy() # Initiate Full Hyper-parameters dictionary\n",
    "                    full_hyp[\"Time_Window_pp\"] = pp\n",
    "                    full_hyp[\"Full_Name\"] = arch[\"Model_Name\"]+f'_{pp}pp'\n",
    "                    full_hyp[\"Full_Name\"] += f'_{RF[2]}_seed{seed}_{\"\".join(segms_train)}'\n",
    "                    # Train the model (if not trained yet):\n",
    "                    if full_hyp[\"Full_Name\"] not in trained_models:\n",
    "                        N_models += 1 # Update number of trainable models\n",
    "                        full_hyp[\"Train_Segms\"] = \"\".join(segms_train)\n",
    "                        full_hyp[\"Test_Segms\"] = \"\".join(segms_test)\n",
    "                        if not quick_timing_test:\n",
    "                            # Prepare Time windows:\n",
    "                            for t_wdw in t_wdws_train:\n",
    "                                t_wdw.pp = pp # Define time window's points\n",
    "                                t_wdw.window_data() # Window data\n",
    "                            for t_wdw in t_wdws_test:\n",
    "                                t_wdw.pp = pp # Define time window's points\n",
    "                                t_wdw.window_data() # Window data\n",
    "                            # Train the model:\n",
    "                            keras.backend.clear_session()\n",
    "                            ML_model = ML_Model(full_hyp,seed=seed)\n",
    "                            res_train = ML_model.train_model(t_wdws_train,RF,savefigs_path=savefigs_path,\n",
    "                                                             exp_model_path=exp_model_path)\n",
    "                            # Test the model:\n",
    "                            res_test = ML_model.test_model(t_wdws_test,RF,savefigs_path=savefigs_path)\n",
    "                            # Update results:\n",
    "                            results = dict(list(res_train.items())+list(res_test.items()))\n",
    "                            pd_results.loc[len(pd_results)] = results\n",
    "                            # Export .csv file (overwrites in everystep):\n",
    "                            B_comps = ''.join([b for b in full_hyp[\"Magnetic_Components\"]])\n",
    "                            name = f'AI_S2_{len(pp_opts)}ppOptions_{len(seed_opts)}seeds'\n",
    "                            name += f'_{len(RF_opts)}RFs_comps{B_comps}.csv'\n",
    "                            pd_results.to_csv(results_path+name, index=False)\n",
    "\n",
    "    if quick_timing_test:\n",
    "        print('-'*10,' QUICK TIMING TEST MODE ','-'*10)\n",
    "        print('Running dry test for 5 epochs...')\n",
    "        time.sleep(1)\n",
    "        # Only train last ML model:\n",
    "        full_hyp['Epochs'] = 5\n",
    "        start = time.time()\n",
    "        keras.backend.clear_session()\n",
    "        # Prepare Time windows:\n",
    "        for t_wdw in t_wdws_train:\n",
    "            t_wdw.pp = pp # Define time window's points\n",
    "            t_wdw.window_data() # Window data\n",
    "        for t_wdw in t_wdws_test:\n",
    "            t_wdw.pp = pp # Define time window's points\n",
    "            t_wdw.window_data() # Window data\n",
    "        # Train model:\n",
    "        ML_model = ML_Model(full_hyp,seed=seed)\n",
    "        _ = ML_model.train_model(t_wdws_train,RF)\n",
    "        _ = ML_model.test_model(t_wdws_test,RF)\n",
    "        end = time.time()\n",
    "        elapsed_time = end - start # [s]\n",
    "        single_model_est_time = elapsed_time/5*arch['Epochs']/60 # [min]\n",
    "        # Print estimated times:\n",
    "        print('\\n','-'*40,'\\n')\n",
    "        print(f'Trainable models in this training session:',N_models)\n",
    "        print(f'Estimated training time per model: {np.round(single_model_est_time,1)} min')\n",
    "        print(f'Estimated total time: {np.round(single_model_est_time*N_models/60,1)} hours')\n",
    "        print('\\n','-'*10,' IMPORTANT ','-'*10,'\\n')\n",
    "        print('If you want to train all models, select quick_timing_test=False')\n",
    "            \n",
    "    return pd_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8462a3c9-f77c-4052-a48e-a04dedafc17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_stage3(arch_opts,seed_opts,RF_opts,\n",
    "                 t_wdws_train,t_wdws_test,savefigs_path=None,\n",
    "                 exp_model_path=None,results_path='./',\n",
    "                 check_rep_model=None,quick_timing_test=False):\n",
    "    \"\"\"\n",
    "    Training procedure for Stage 3, focusing on ML model's main architecture. It trains\n",
    "    many ML models using different options for seeds and rotational frames.\n",
    "    It returns and exports a dataframe with the results.\n",
    "\n",
    "    --- Inputs ---\n",
    "\n",
    "    {arch_opts}: List; each element is a dictionary with the ML model hyper-parameters,\n",
    "    see {self.hyps} attribute for <ML_Model> object.\n",
    "    {seed_opts}: List; each element is an integer meaning a random initialization seed.\n",
    "    {RF_opts}: List; each element is a list with the format [Numpy array,Numeric,String];\n",
    "    meaning [rotation axis in (x,y,z) format, rotation angle in degree, RF name].\n",
    "    If RF[2]='RF1', then the data is kept in the original frame.\n",
    "    {t_wdws_train}: List; each element is a <Time_Wdw> object that will be used for\n",
    "    the training process. The number of points for each time window doesn't matter.\n",
    "    {t_wdws_test}: List; each element is a <Time_Wdw> object that will be used for\n",
    "    the testing process. The number of points for each time window doesn't matter.\n",
    "    {savefigs_path}: String; if specified, saves the training figures in .png format by default.\n",
    "    {save_format}: String; Choose the saving format, 'png' by default, don't include the dot.\n",
    "    {exp_model_path}: String; if specified, exports the ML model.\n",
    "    {results_path}: String; path for exporting results. Default: current directory.\n",
    "    {check_rep_model}: String or None; if provided, use a .csv file as a reference, same format\n",
    "    as the output of this function, to skip any already trained model. Default: None.\n",
    "    {quick_timing_test}: Boolean. If True, ONLY runs a dry test (no savings of any type) for 5 epochs\n",
    "    and estimate the total training times.\n",
    "    \n",
    "    --- Outputs ---\n",
    "\n",
    "    {pd_results}: Pandas dataframe; information about the ML models' results.\n",
    "    \n",
    "    \"\"\"\n",
    "    # If provided, load the reference file:\n",
    "    if check_rep_model is not None:\n",
    "        pd_ref = pd.read_csv(check_rep_model)\n",
    "        trained_models = list(pd_ref[\"Full_Name\"]) # Extract the full names of trained ML models\n",
    "    else:\n",
    "        trained_models = []\n",
    "    # Initiate dataframe:\n",
    "    pd_results = pd.DataFrame(columns=['Full_Name','Wdw_pp','Mag_Comps','RF','Seed',\n",
    "                                       'Train_Segms','Test_Segms',\n",
    "                                       'Batch','Epochs','p_val','Activ_func','Optimizer',\n",
    "                                       'Learn_rate','Model_Name','Best_MAE_val',\n",
    "                                       'Best_MAE_train','MAE_test',\n",
    "                                       'z_thres','Acc_Val_z','Acc_Test_z'])\n",
    "    # Prepare time windows:\n",
    "    segms_train = [time_wdw.name for time_wdw in t_wdws_train] # List with training segments' names\n",
    "    segms_test = [time_wdw.name for time_wdw in t_wdws_test] # List with testing segments' names\n",
    "    for subset in [t_wdws_train,t_wdws_test]:\n",
    "        for t_wdw in subset: \n",
    "            t_wdw.window_data()    \n",
    "    # Train all models:\n",
    "    N_models = 0 # Initiatie auxiliar count\n",
    "    for arch in arch_opts: # Iterate over architectures\n",
    "        for RF in RF_opts: # Iterate over rotational frames\n",
    "            for seed in seed_opts: # Iterate over random initialization seeds\n",
    "                # Prepare hyper-parameter options for model:\n",
    "                full_hyp = arch.copy() # Initiate Full Hyper-parameters dictionary\n",
    "                full_hyp[\"Full_Name\"] = arch[\"Model_Name\"]+f'_{RF[2]}_seed{seed}_{\"\".join(segms_train)}'\n",
    "                # Train the model (if not trained yet):\n",
    "                if full_hyp[\"Full_Name\"] not in trained_models:\n",
    "                    N_models += 1 # Update number of trainable models\n",
    "                    full_hyp[\"Train_Segms\"] = \"\".join(segms_train)\n",
    "                    full_hyp[\"Test_Segms\"] = \"\".join(segms_test)\n",
    "                    if not quick_timing_test:\n",
    "                        # Train the model:\n",
    "                        keras.backend.clear_session()\n",
    "                        ML_model = ML_Model(full_hyp,seed=seed)\n",
    "                        res_train = ML_model.train_model(t_wdws_train,RF,savefigs_path=savefigs_path,\n",
    "                                                         exp_model_path=exp_model_path)\n",
    "                        # Test the model:\n",
    "                        res_test = ML_model.test_model(t_wdws_test,RF,savefigs_path=savefigs_path)\n",
    "                        # Update results:\n",
    "                        results = dict(list(res_train.items())+list(res_test.items()))\n",
    "                        pd_results.loc[len(pd_results)] = results\n",
    "                        # Export .csv file (overwrites in everystep):\n",
    "            \n",
    "                        name = f'AI_S3_{len(seed_opts)}seeds_{len(RF_opts)}RFs.csv'\n",
    "                        pd_results.to_csv(results_path+name, index=False)\n",
    "\n",
    "    if quick_timing_test:\n",
    "        print('-'*10,' QUICK TIMING TEST MODE ','-'*10)\n",
    "        print('Running dry test for 5 epochs...')\n",
    "        time.sleep(1)\n",
    "        # Only train last ML model:\n",
    "        full_hyp['Epochs'] = 5\n",
    "        start = time.time()\n",
    "        keras.backend.clear_session()\n",
    "        # Train model:\n",
    "        ML_model = ML_Model(full_hyp,seed=seed)\n",
    "        _ = ML_model.train_model(t_wdws_train,RF)\n",
    "        _ = ML_model.test_model(t_wdws_test,RF)\n",
    "        end = time.time()\n",
    "        elapsed_time = end - start # [s]\n",
    "        single_model_est_time = elapsed_time/5*arch['Epochs']/60 # [min]\n",
    "        # Print estimated times:\n",
    "        print('\\n','-'*40,'\\n')\n",
    "        print(f'Trainable models in this training session:',N_models)\n",
    "        print(f'Estimated training time per model: {np.round(single_model_est_time,1)} min')\n",
    "        print(f'Estimated total time: {np.round(single_model_est_time*N_models/60,1)} hours')\n",
    "        print('\\n','-'*10,' IMPORTANT ','-'*10,'\\n')\n",
    "        print('If you want to train all models, select quick_timing_test=False')\n",
    "        \n",
    "    return pd_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b1e3fca-d585-4978-80f8-c77a3e201c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_stage4(gen_hyps,activ_opts,optim_opts,lr_opts,seed_opts,\n",
    "                 RF_opts,t_wdws_train,t_wdws_test,savefigs_path=None,\n",
    "                 exp_model_path=None,results_path='./',\n",
    "                 check_rep_model=None,quick_timing_test=False):\n",
    "    \"\"\"\n",
    "    Training procedure for Stage 4, focusing on ML model's hyper-parameters. It trains\n",
    "    many ML models using different options for seeds and rotational frames.\n",
    "    It returns and exports a dataframe with the results.\n",
    "\n",
    "    --- Inputs ---\n",
    "\n",
    "    {gen_hyps}: Dictionary, general hyper-parameters for all ML models.\n",
    "    {activ_opts}: List; each element is an activation function to be used in all layers\n",
    "    except the last one.\n",
    "    {optim_opts}: List; each element is an optimizer.\n",
    "    {lr_opts}: List; each element is a learning rate value.    \n",
    "    {seed_opts}: List; each element is an integer meaning a random initialization seed.\n",
    "    {RF_opts}: List; each element is a list with the format [Numpy array,Numeric,String];\n",
    "    meaning [rotation axis in (x,y,z) format, rotation angle in degree, RF name].\n",
    "    If RF[2]='RF1', then the data is kept in the original frame.\n",
    "    {t_wdws_train}: List; each element is a <Time_Wdw> object that will be used for\n",
    "    the training process. The number of points for each time window doesn't matter.\n",
    "    {t_wdws_test}: List; each element is a <Time_Wdw> object that will be used for\n",
    "    the testing process. The number of points for each time window doesn't matter.\n",
    "    {savefigs_path}: String; if specified, saves the training figures in .png format by default.\n",
    "    {save_format}: String; Choose the saving format, 'png' by default, don't include the dot.\n",
    "    {exp_model_path}: String; if specified, exports the ML model.\n",
    "    {results_path}: String; path for exporting results. Default: current directory.\n",
    "    {check_rep_model}: String or None; if provided, use a .csv file as a reference, same format\n",
    "    as the output of this function, to skip any already trained model. Default: None.\n",
    "    {quick_timing_test}: Boolean. If True, ONLY runs a dry test (no savings of any type) for 5 epochs\n",
    "    and estimate the total training times.\n",
    "    \n",
    "    --- Outputs ---\n",
    "\n",
    "    {pd_results}: Pandas dataframe; information about the ML models' results.\n",
    "    \n",
    "    \"\"\"\n",
    "    # If provided, load the reference file:\n",
    "    if check_rep_model is not None:\n",
    "        pd_ref = pd.read_csv(check_rep_model)\n",
    "        trained_models = list(pd_ref[\"Full_Name\"]) # Extract the full names of trained ML models\n",
    "    else:\n",
    "        trained_models = []\n",
    "    # Initiate dataframe:\n",
    "    pd_results = pd.DataFrame(columns=['Full_Name','Wdw_pp','Mag_Comps','RF','Seed',\n",
    "                                       'Train_Segms','Test_Segms',\n",
    "                                       'Batch','Epochs','p_val','Activ_func','Optimizer',\n",
    "                                       'Learn_rate','Model_Name','Best_MAE_val',\n",
    "                                       'Best_MAE_train','MAE_test',\n",
    "                                       'z_thres','Acc_Val_z','Acc_Test_z'])    \n",
    "   # Prepare time windows:\n",
    "    segms_train = [time_wdw.name for time_wdw in t_wdws_train] # List with training segments' names\n",
    "    segms_test = [time_wdw.name for time_wdw in t_wdws_test] # List with testing segments' names\n",
    "    for subset in [t_wdws_train,t_wdws_test]:\n",
    "        for t_wdw in subset: \n",
    "            t_wdw.window_data()\n",
    "    # Train all models:\n",
    "    N_models = 0 # Initiatie auxiliar count    \n",
    "    for activ in activ_opts: \n",
    "        for optim in optim_opts: \n",
    "            for lr in lr_opts: \n",
    "                for RF in RF_opts: # Iterate over rotational frames\n",
    "                    for seed in seed_opts: # Iterate over random initialization seeds\n",
    "                        # Prepare hyper-parameter options for model:\n",
    "                        full_hyp = gen_hyps.copy() # Initiate Full Hyper-parameters dictionary\n",
    "                        full_hyp[\"Activation_Function\"] = activ\n",
    "                        full_hyp[\"Optimizer\"] = optim\n",
    "                        full_hyp[\"Learning_Rate\"] = lr\n",
    "                        fullname = f\"activ{activ}_optim{optim}\"\n",
    "                        fullname += f\"_lr{lr}_{RF[2]}_seed{seed}\"\n",
    "                        fullname += f'_{\"\".join(segms_train)}'\n",
    "                        full_hyp[\"Full_Name\"] = fullname\n",
    "                        # Train the model (if not trained yet):\n",
    "                        if full_hyp[\"Full_Name\"] not in trained_models:\n",
    "                            N_models += 1 # Update number of trainable models\n",
    "                            full_hyp[\"Train_Segms\"] = \"\".join(segms_train)\n",
    "                            full_hyp[\"Test_Segms\"] = \"\".join(segms_test)\n",
    "                            if not quick_timing_test:\n",
    "                                # Train the model:\n",
    "                                keras.backend.clear_session()\n",
    "                                ML_model = ML_Model(full_hyp,seed=seed)\n",
    "                                res_train = ML_model.train_model(t_wdws_train,RF,savefigs_path=savefigs_path,\n",
    "                                                                 exp_model_path=exp_model_path)\n",
    "                                # Test the model:\n",
    "                                res_test = ML_model.test_model(t_wdws_test,RF,savefigs_path=savefigs_path)\n",
    "                                # Update results:\n",
    "                                results = dict(list(res_train.items())+list(res_test.items()))\n",
    "                                pd_results.loc[len(pd_results)] = results\n",
    "                                # Export .csv file (overwrites in everystep):\n",
    "                                B_comps = ''.join([b for b in full_hyp[\"Magnetic_Components\"]])\n",
    "                                name = f'AI_S4_{len(seed_opts)}seeds_{len(RF_opts)}RFs.csv'\n",
    "                                pd_results.to_csv(results_path+name, index=False)\n",
    "            \n",
    "    if quick_timing_test:\n",
    "        print('-'*10,' QUICK TIMING TEST MODE ','-'*10)\n",
    "        print('Running dry test for 5 epochs...')\n",
    "        time.sleep(1)\n",
    "        # Only train last ML model:\n",
    "        full_hyp['Epochs'] = 5\n",
    "        start = time.time()\n",
    "        keras.backend.clear_session()\n",
    "        # Train model:\n",
    "        ML_model = ML_Model(full_hyp,seed=seed)\n",
    "        _ = ML_model.train_model(t_wdws_train,RF)\n",
    "        _ = ML_model.test_model(t_wdws_test,RF)\n",
    "        end = time.time()\n",
    "        elapsed_time = end - start # [s]\n",
    "        single_model_est_time = elapsed_time/5*gen_hyps['Epochs']/60 # [min]\n",
    "        # Print estimated times:\n",
    "        print('\\n','-'*40,'\\n')\n",
    "        print(f'Trainable models in this training session:',N_models)\n",
    "        print(f'Estimated training time per model: {np.round(single_model_est_time,1)} min')\n",
    "        print(f'Estimated total time: {np.round(single_model_est_time*N_models/60,1)} hours')\n",
    "        print('\\n','-'*10,' IMPORTANT ','-'*10,'\\n')\n",
    "        print('If you want to train all models, select quick_timing_test=False')\n",
    "        \n",
    "    return pd_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "505846f0-5ff8-4759-b8a6-1a83ab9d6d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_stage5(gen_hyps,filter_opts,drop_opts,seed_opts,\n",
    "                 RF_opts,t_wdws_train,t_wdws_test,savefigs_path=None,\n",
    "                 exp_model_path=None,results_path='./',\n",
    "                 check_rep_model=None,quick_timing_test=False):\n",
    "    \"\"\"\n",
    "    Training procedure for Stage 5, focusing on ML model's fine architecture.\n",
    "    It trains many ML models using different options for seeds and rotational frames.\n",
    "    It returns and exports a dataframe with the results.\n",
    "\n",
    "    --- Inputs ---\n",
    "\n",
    "    {gen_hyps}: Dictionary, general hyper-parameters for all ML models.\n",
    "    {filter_opts}: List, each element is an option for the convolutional layers.\n",
    "    {drop_opts}: List; each element is a value for the dropout fraction in dense layers.\n",
    "    {seed_opts}: List; each element is an integer meaning a random initialization seed.\n",
    "    {RF_opts}: List; each element is a list with the format [Numpy array,Numeric,String];\n",
    "    meaning [rotation axis in (x,y,z) format, rotation angle in degree, RF name].\n",
    "    If RF[2]='RF1', then the data is kept in the original frame.\n",
    "    {t_wdws_train}: List; each element is a <Time_Wdw> object that will be used for\n",
    "    the training process. The number of points for each time window doesn't matter.\n",
    "    {t_wdws_test}: List; each element is a <Time_Wdw> object that will be used for\n",
    "    the testing process. The number of points for each time window doesn't matter.\n",
    "    {savefigs_path}: String; if specified, saves the training figures in .png format by default.\n",
    "    {save_format}: String; Choose the saving format, 'png' by default, don't include the dot.\n",
    "    {exp_model_path}: String; if specified, exports the ML model.\n",
    "    {results_path}: String; path for exporting results. Default: current directory.\n",
    "    {check_rep_model}: String or None; if provided, use a .csv file as a reference, same format\n",
    "    as the output of this function, to skip any already trained model. Default: None.\n",
    "    {quick_timing_test}: Boolean. If True, ONLY runs a dry test (no savings of any type) for 5 epochs\n",
    "    and estimate the total training times.\n",
    "    \n",
    "    --- Outputs ---\n",
    "\n",
    "    {pd_results}: Pandas dataframe; information about the ML models' results.\n",
    "    \n",
    "    \"\"\"\n",
    "    # If provided, load the reference file:\n",
    "    if check_rep_model is not None:\n",
    "        pd_ref = pd.read_csv(check_rep_model)\n",
    "        trained_models = list(pd_ref[\"Full_Name\"]) # Extract the full names of trained ML models\n",
    "    else:\n",
    "        trained_models = []\n",
    "    # Initiate dataframe:\n",
    "    pd_results = pd.DataFrame(columns=['Full_Name','Wdw_pp','Mag_Comps','RF','Seed',\n",
    "                                       'Train_Segms','Test_Segms',\n",
    "                                       'Batch','Epochs','p_val','Activ_func','Optimizer',\n",
    "                                       'Learn_rate','Model_Name','Best_MAE_val',\n",
    "                                       'Best_MAE_train','MAE_test',\n",
    "                                       'z_thres','Acc_Val_z','Acc_Test_z'])       \n",
    "    # Prepare time windows:\n",
    "    segms_train = [time_wdw.name for time_wdw in t_wdws_train] # List with training segments' names\n",
    "    segms_test = [time_wdw.name for time_wdw in t_wdws_test] # List with testing segments' names\n",
    "    for subset in [t_wdws_train,t_wdws_test]:\n",
    "        for t_wdw in subset: \n",
    "            t_wdw.window_data()\n",
    "    # Train all models:\n",
    "    N_models = 0 # Initiatie auxiliar count    \n",
    "    for filter in filter_opts: \n",
    "        for drop in drop_opts: \n",
    "            for RF in RF_opts: # Iterate over rotational frames\n",
    "                for seed in seed_opts: # Iterate over random initialization seeds\n",
    "                    # Prepare hyper-parameter options for model:\n",
    "                    full_hyp = gen_hyps.copy() # Initiate Full Hyper-parameters dictionary\n",
    "                    full_hyp[\"Conv_Layers\"] = filter\n",
    "                    full_hyp[\"Dropout_Fraction\"] = drop\n",
    "                    str_filters = '_'.join([str(f[0]) for f in filter])\n",
    "                    fullname = f\"Filters{str_filters}_dropout{drop}\"\n",
    "                    fullname += f\"_{RF[2]}_seed{seed}_{''.join(segms_train)}\"\n",
    "                    full_hyp[\"Full_Name\"] = fullname\n",
    "                    # Train the model (if not trained yet):\n",
    "                    if full_hyp[\"Full_Name\"] not in trained_models:\n",
    "                        N_models += 1 # Update number of trainable models\n",
    "                        full_hyp[\"Train_Segms\"] = \"\".join(segms_train)\n",
    "                        full_hyp[\"Test_Segms\"] = \"\".join(segms_test)\n",
    "                        if not quick_timing_test:\n",
    "                            # Train the model:\n",
    "                            keras.backend.clear_session()\n",
    "                            ML_model = ML_Model(full_hyp,seed=seed)\n",
    "                            res_train = ML_model.train_model(t_wdws_train,RF,savefigs_path=savefigs_path,\n",
    "                                                             exp_model_path=exp_model_path)\n",
    "                            # Test the model:\n",
    "                            res_test = ML_model.test_model(t_wdws_test,RF,savefigs_path=savefigs_path)\n",
    "                            # Update results:\n",
    "                            results = dict(list(res_train.items())+list(res_test.items()))\n",
    "                            pd_results.loc[len(pd_results)] = results\n",
    "                            # Export .csv file (overwrites in everystep):\n",
    "                            name = f'AI_S5_{len(seed_opts)}seeds_{len(RF_opts)}RFs.csv'\n",
    "                            pd_results.to_csv(results_path+name, index=False)\n",
    "            \n",
    "    if quick_timing_test:\n",
    "        print('-'*10,' QUICK TIMING TEST MODE ','-'*10)\n",
    "        print('Running dry test for 5 epochs...')\n",
    "        time.sleep(1)\n",
    "        # Only train last ML model:\n",
    "        full_hyp['Epochs'] = 5\n",
    "        start = time.time()\n",
    "        keras.backend.clear_session()\n",
    "        # Train model:\n",
    "        ML_model = ML_Model(full_hyp,seed=seed)\n",
    "        _ = ML_model.train_model(t_wdws_train,RF)\n",
    "        _ = ML_model.test_model(t_wdws_test,RF)\n",
    "        end = time.time()\n",
    "        elapsed_time = end - start # [s]\n",
    "        single_model_est_time = elapsed_time/5*gen_hyps['Epochs']/60 # [min]\n",
    "        # Print estimated times:\n",
    "        print('\\n','-'*40,'\\n')\n",
    "        print(f'Trainable models in this training session:',N_models)\n",
    "        print(f'Estimated training time per model: {np.round(single_model_est_time,1)} min')\n",
    "        print(f'Estimated total time: {np.round(single_model_est_time*N_models/60,1)} hours')\n",
    "        print('\\n','-'*10,' IMPORTANT ','-'*10,'\\n')\n",
    "        print('If you want to train all models, select quick_timing_test=False')\n",
    "    \n",
    "    return pd_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0dc3b965-d43c-47a7-a018-8006803f4924",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_stage6(gen_hyps,p_train_opts,N_augm_opts,noise_opts,\n",
    "                 seed_opts,RF_opts,t_wdws_train,t_wdws_test,\n",
    "                 savefigs_path=None,exp_model_path=None,results_path='./',\n",
    "                 check_rep_model=None,quick_timing_test=False):\n",
    "    \"\"\"\n",
    "    Training procedure for Stage 6, focusing on the effect of data augmentation and\n",
    "    the size of the training dataset.\n",
    "    It trains many ML models using different options for seeds and rotational frames.\n",
    "    It returns and exports a dataframe with the results.\n",
    "\n",
    "    --- Inputs ---\n",
    "\n",
    "    {gen_hyps}: Dictionary, general hyper-parameters for all ML models.\n",
    "    {p_train_opts}: List, each element is a fraction between 0 and 1, it is an option for\n",
    "    the fraction of the training dataset that is going to be used.\n",
    "    {N_augm_opts}: List; each element is an integer, it is an option the number of times\n",
    "    that the original training dataset will be augmented.\n",
    "    {noise_opts}: List, each element is a list comprised of 3 float numbers, representing an\n",
    "    option for the noise intensity for data augmentation, in [nT] units.\n",
    "    {seed_opts}: List; each element is an integer meaning a random initialization seed.\n",
    "    {RF_opts}: List; each element is a list with the format [Numpy array,Numeric,String];\n",
    "    meaning [rotation axis in (x,y,z) format, rotation angle in degree, RF name].\n",
    "    If RF[2]='RF1', then the data is kept in the original frame.\n",
    "    {t_wdws_train}: List; each element is a <Time_Wdw> object that will be used for\n",
    "    the training process. The number of points for each time window doesn't matter.\n",
    "    {t_wdws_test}: List; each element is a <Time_Wdw> object that will be used for\n",
    "    the testing process. The number of points for each time window doesn't matter.\n",
    "    {savefigs_path}: String; if specified, saves the training figures in .png format by default.\n",
    "    {save_format}: String; Choose the saving format, 'png' by default, don't include the dot.\n",
    "    {exp_model_path}: String; if specified, exports the ML model.\n",
    "    {results_path}: String; path for exporting results. Default: current directory.\n",
    "    {check_rep_model}: String or None; if provided, use a .csv file as a reference, same format\n",
    "    as the output of this function, to skip any already trained model. Default: None.\n",
    "    {quick_timing_test}: Boolean. If True, ONLY runs a dry test (no savings of any type) for 5 epochs\n",
    "    and estimate the total training times.\n",
    "    \n",
    "    --- Outputs ---\n",
    "\n",
    "    {pd_results}: Pandas dataframe; information about the ML models' results.\n",
    "    \n",
    "    \"\"\"\n",
    "    # If provided, load the reference file:\n",
    "    if check_rep_model is not None:\n",
    "        pd_ref = pd.read_csv(check_rep_model)\n",
    "        trained_models = list(pd_ref[\"Full_Name\"]) # Extract the full names of trained ML models\n",
    "    else:\n",
    "        trained_models = []\n",
    "    # Initiate dataframe:\n",
    "    pd_results = pd.DataFrame(columns=['Full_Name','Wdw_pp','Mag_Comps','RF','Seed',\n",
    "                                       'Train_Segms','Test_Segms',\n",
    "                                       'p_train','N_augm','Bx_noise','By_noise','Bz_noise',\n",
    "                                       'Batch','Epochs','p_val','Activ_func','Optimizer',\n",
    "                                       'Learn_rate','Model_Name','Best_MAE_val',\n",
    "                                       'Best_MAE_train','MAE_test',\n",
    "                                       'z_thres','Acc_Val_z','Acc_Test_z'])       \n",
    "    # Prepare time windows:\n",
    "    segms_train = [time_wdw.name for time_wdw in t_wdws_train] # List with training segments' names\n",
    "    segms_test = [time_wdw.name for time_wdw in t_wdws_test] # List with testing segments' names\n",
    "    for t_wdw in t_wdws_test: \n",
    "        t_wdw.window_data()    \n",
    "    # Train all models:\n",
    "    N_models = 0 # Initiatie auxiliar count    \n",
    "    for p_train in p_train_opts:\n",
    "        for N_augm in N_augm_opts: \n",
    "            for noise in noise_opts:\n",
    "                for RF in RF_opts: # Iterate over rotational frames\n",
    "                    for seed in seed_opts: # Iterate over random initialization seeds\n",
    "                        # Prepare hyper-parameter options for model:\n",
    "                        full_hyp = gen_hyps.copy() # Initiate Full Hyper-parameters dictionary\n",
    "                        fullname = f\"ptrain{p_train}_Naugm{N_augm}_\"\n",
    "                        fullname += f\"noiseBx{noise[0]}_By{noise[1]}_Bz{noise[2]}_nT\"\n",
    "                        fullname += f\"_{RF[2]}_seed{seed}_{''.join(segms_train)}\"\n",
    "                        full_hyp[\"Full_Name\"] = fullname\n",
    "                        # Train the model (if not trained yet):\n",
    "                        if full_hyp[\"Full_Name\"] not in trained_models:\n",
    "                            N_models += 1 # Update number of trained models\n",
    "                            full_hyp[\"Train_Segms\"] = \"\".join(segms_train)\n",
    "                            full_hyp[\"Test_Segms\"] = \"\".join(segms_test)\n",
    "                            if not quick_timing_test:\n",
    "                                # Reduce original training dataset:\n",
    "                                t_wdws_train_reduced = [copy_and_reduce_TimeWdw(time_wdw,p_train) for time_wdw in t_wdws_train]        \n",
    "                                # Augmentate dataset:\n",
    "                                for t_wdw in t_wdws_train_reduced:\n",
    "                                    t_wdw.window_data(N_augm=N_augm,\n",
    "                                                      Bx_noise=noise[0], By_noise=noise[1], Bz_noise=noise[2])\n",
    "                                # Train the model:\n",
    "                                keras.backend.clear_session()\n",
    "                                ML_model = ML_Model(full_hyp,seed=seed)\n",
    "                                res_train = ML_model.train_model(t_wdws_train_reduced,RF,savefigs_path=savefigs_path,\n",
    "                                                                 exp_model_path=exp_model_path)\n",
    "                                # Test the model:\n",
    "                                res_test = ML_model.test_model(t_wdws_test,RF,savefigs_path=savefigs_path)\n",
    "                                # Update results:\n",
    "                                results = dict(list(res_train.items())+list(res_test.items()))\n",
    "                                results['p_train'] = p_train\n",
    "                                results['N_augm'] = N_augm\n",
    "                                results['Bx_noise'] = noise[0] # [nT]\n",
    "                                results['By_noise'] = noise[1] # [nT]\n",
    "                                results['Bz_noise'] = noise[2] # [nT]\n",
    "                                pd_results.loc[len(pd_results)] = results\n",
    "                                # Export .csv file (overwrites in everystep):\n",
    "                                name = f'AI_S6_{len(p_train_opts)}frac_opts_{len(N_augm_opts)}'\n",
    "                                name += f'N_augm_opts_{len(noise_opts)}_noise_opts.csv'\n",
    "                                pd_results.to_csv(results_path+name, index=False)\n",
    "            \n",
    "    if quick_timing_test:\n",
    "        print('-'*10,' QUICK TIMING TEST MODE ','-'*10)\n",
    "        print('Running dry test for 5 epochs...')\n",
    "        time.sleep(1)\n",
    "        # Only train last ML model:\n",
    "        full_hyp['Epochs'] = 5\n",
    "        start = time.time()\n",
    "        keras.backend.clear_session()\n",
    "        # Prepare Time windows:\n",
    "        t_wdws_train_reduced = [copy_and_reduce_TimeWdw(time_wdw,p_train) for time_wdw in t_wdws_train]        \n",
    "        # Augmentate dataset:\n",
    "        for t_wdw in t_wdws_train_reduced:\n",
    "            t_wdw.window_data(N_augm=N_augm,Bx_noise=noise[0],\n",
    "                              By_noise=noise[1], Bz_noise=noise[2])\n",
    "        # Train model:\n",
    "        ML_model = ML_Model(full_hyp,seed=seed)\n",
    "        _ = ML_model.train_model(t_wdws_train_reduced,RF)\n",
    "        _ = ML_model.test_model(t_wdws_test,RF)\n",
    "        end = time.time()\n",
    "        elapsed_time = end - start # [s]\n",
    "        single_model_est_time = elapsed_time/5*gen_hyps['Epochs']/60 # [min]\n",
    "        # Print estimated times:\n",
    "        print('\\n','-'*40,'\\n')\n",
    "        print(f'Trainable models in this training session:',N_models)\n",
    "        print(f'Estimated training time per model: {np.round(single_model_est_time,1)} min')\n",
    "        print(f'Estimated total time: {np.round(single_model_est_time*N_models/60,1)} hours')\n",
    "        print('\\n','-'*10,' IMPORTANT ','-'*10,'\\n')\n",
    "        print('If you want to train all models, select quick_timing_test=False')\n",
    "        \n",
    "    return pd_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ae9bb85-b9e5-4875-a6e0-337ca3a34b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_stage7(gen_hyps,t_wdws_train,t_wdws_test,\n",
    "                 seed_opts,savefigs_path=None,\n",
    "                 results_path='./',check_rep_model=None,\n",
    "                 quick_timing_test=False):\n",
    "    \"\"\"\n",
    "    Train a single model, export it and return the predictions, using the rotated frames\n",
    "    provided in the hyperparameters description.\n",
    "\n",
    "    --- Inputs ---\n",
    "\n",
    "    {gen_hyps}: Dictionary, general hyper-parameters for all ML models.\n",
    "    {t_wdws_train}: List; each element is a <Time_Wdw> object that will be used for\n",
    "    the training process. The number of points for each time window doesn't matter.\n",
    "    {t_wdws_test}: List; each element is a <Time_Wdw> object that will be used for\n",
    "    the testing process. The number of points for each time window doesn't matter.\n",
    "    {seed_opts}: List; each element is an integer meaning a random initialization seed.\n",
    "    {savefigs_path}: String; if specified, saves the training figures in .png format by default.\n",
    "    {save_format}: String; Choose the saving format, 'png' by default, don't include the dot.\n",
    "    {results_path}: String; path for exporting results. Default: current directory.\n",
    "    {check_rep_model}: String or None; if provided, use a .csv file as a reference, same format\n",
    "    as the output of this function, to skip any already trained model. Default: None.\n",
    "    {quick_timing_test}: Boolean. If True, ONLY runs a dry test (no savings of any type) for 5 epochs\n",
    "    and estimate the total training times.    \n",
    "    \"\"\"\n",
    "    # If provided, load the reference file:\n",
    "    if check_rep_model is not None:\n",
    "        pd_ref = pd.read_csv(check_rep_model)\n",
    "        trained_models = list(pd_ref[\"Full_Name\"]) # Extract the full names of trained ML models\n",
    "    else:\n",
    "        trained_models = []\n",
    "    # Initiate dataframe:\n",
    "    df_results = pd.DataFrame(columns=['Full_Name','Wdw_pp','Mag_Comps','RF','Seed',\n",
    "                                   'Train_Segms','Test_Segms',\n",
    "                                   'p_train','N_augm','Bx_noise','By_noise','Bz_noise',\n",
    "                                   'Batch','Epochs','p_val','Activ_func','Optimizer',\n",
    "                                   'Learn_rate','Model_Name','Best_MAE_val',\n",
    "                                   'Best_MAE_train','MAE_test',\n",
    "                                   'z_thres','Acc_Val_z','Acc_Test_z'])\n",
    "    \n",
    "    # Start preparing the ML model name:\n",
    "    ML_name = f'MLmodel_{gen_hyps[\"Model_Name\"]}' # Model name\n",
    "    segms_train = [time_wdw.name for time_wdw in t_wdws_train] # ID name\n",
    "    segms_test = [time_wdw.name for time_wdw in t_wdws_test] # ID name\n",
    "    gen_hyps[\"Train_Segms\"] = \"\".join(segms_train) # Add training segments information\n",
    "    gen_hyps[\"Test_Segms\"] = \"\".join(segms_test) # Add testing segments information\n",
    "    ML_name += f'_{gen_hyps[\"Train_Segms\"]}' # Update name\n",
    "    \n",
    "    # Reduce training dataset (if requested) and window data:\n",
    "    if gen_hyps[\"p_train\"] < 1:\n",
    "        t_wdws_train_reduced = [copy_and_reduce_TimeWdw(time_wdw,p_train) for time_wdw in t_wdws_train]\n",
    "        ML_name += f'_ptrain{gen_hyps[\"p_train\"]}' # Update name\n",
    "    else: \n",
    "        t_wdws_train_reduced = t_wdws_train\n",
    "\n",
    "    # Window test data:\n",
    "    for t_wdw in t_wdws_test: \n",
    "        t_wdw.window_data()    \n",
    "        \n",
    "    # Augment training dataset (if requested) and window training data:\n",
    "    ML_name += f'_Naugm{gen_hyps[\"N_augm\"]}'\n",
    "    if gen_hyps[\"N_augm\"] > 0:\n",
    "        ML_name += f'_noise_{gen_hyps[\"noise\"][0]}_' # Update name\n",
    "        ML_name += f'{gen_hyps[\"noise\"][1]}_{gen_hyps[\"noise\"][2]}_nT' # Update name\n",
    "    for t_wdw in t_wdws_train_reduced:\n",
    "        t_wdw.window_data(N_augm=gen_hyps[\"N_augm\"],Bx_noise=gen_hyps[\"noise\"][0], \n",
    "                          By_noise=gen_hyps[\"noise\"][1], Bz_noise=gen_hyps[\"noise\"][2])        \n",
    "\n",
    "    # Train all models, make and save predictions:\n",
    "    N_models = 0 # Initiatie auxiliar count    \n",
    "    predictions = {} # Initiate\n",
    "    for RF in gen_hyps['RF']: # Iterate over rotational frames\n",
    "        for seed in seed_opts: # Iterate over random initialization seeds\n",
    "            full_hyp = gen_hyps.copy() # Initiate Full Hyper-parameters dictionary\n",
    "            full_hyp[\"Full_Name\"] = ML_name + f\"_{RF[2]}_seed{seed}_{''.join(segms_train)}\" # Add full name for the model\n",
    "            if full_hyp[\"Full_Name\"] not in trained_models:\n",
    "                N_models += 1 # Update number of trained models\n",
    "                full_hyp[\"Train_Segms\"] = \"\".join(segms_train)\n",
    "                full_hyp[\"Test_Segms\"] = \"\".join(segms_test)\n",
    "                if not quick_timing_test:\n",
    "                    # Train the model:\n",
    "                    keras.backend.clear_session()\n",
    "                    ML_model = ML_Model(full_hyp,seed=seed)\n",
    "                    res_train = ML_model.train_model(t_wdws_train_reduced,RF,savefigs_path=savefigs_path)\n",
    "                    # Test the model and obtain ground truth and predictions, in [m]:\n",
    "                    res_test, t, true_z, pred_z = ML_model.test_model(t_wdws_test,RF,return_preds=True,\n",
    "                                                                      savefigs_path=savefigs_path)        \n",
    "                    predictions[RF[2]] = [t, true_z, pred_z] # Update dictionary for current RF; [s],[m],[m]\n",
    "                    # Update results:\n",
    "                    results = dict(list(res_train.items())+list(res_test.items())) # Compile results\n",
    "                    df_results.loc[len(df_results)] = results # Add new row in dataframe\n",
    "                    # Export .csv file (overwrites in everystep):\n",
    "                    name = f'AI_S7_{ML_name}_{full_hyp[\"Epochs\"]}.csv'\n",
    "                    df_results.to_csv(results_path+name, index=False)\n",
    "                    # Export predictions file:\n",
    "                    for i in range(len(t)):\n",
    "                        np.savetxt(results_path+f\"Preds_{ML_name}_{RF[2]}_seed{seed}_test{i}.csv\",\n",
    "                                   np.transpose(np.array([t[i],true_z[i], pred_z[i]])),\n",
    "                                   delimiter=\",\",header='time[s]_trueZ[m]_predZ[m]',fmt='%.7e')\n",
    "                        \n",
    "    if quick_timing_test:\n",
    "        print('-'*10,' QUICK TIMING TEST MODE ','-'*10)\n",
    "        print('Running dry test for 5 epochs...')\n",
    "        time.sleep(1)\n",
    "        # Only train last ML model:\n",
    "        full_hyp['Epochs'] = 5\n",
    "        start = time.time()\n",
    "        keras.backend.clear_session()\n",
    "        # Train model:\n",
    "        ML_model = ML_Model(full_hyp,seed=seed)\n",
    "        _ = ML_model.train_model(t_wdws_train,RF)\n",
    "        _ = ML_model.test_model(t_wdws_test,RF)\n",
    "        end = time.time()\n",
    "        elapsed_time = end - start # [s]\n",
    "        single_model_est_time = elapsed_time/5*gen_hyps['Epochs']/60 # [min]\n",
    "        # Print estimated times:\n",
    "        print('\\n','-'*40,'\\n')\n",
    "        print(f'Trainable models in this training session:',N_models)\n",
    "        print(f'Estimated training time per model: {np.round(single_model_est_time,1)} min')\n",
    "        print(f'Estimated total time: {np.round(single_model_est_time*N_models/60,1)} hours')\n",
    "        print('\\n','-'*10,' IMPORTANT ','-'*10,'\\n')\n",
    "        print('If you want to train all models, select quick_timing_test=False')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960958c9-59e0-4ecc-a412-ce2e79c7cd9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py10",
   "language": "python",
   "name": "py10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
