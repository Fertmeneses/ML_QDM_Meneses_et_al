{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f111fbfc",
   "metadata": {},
   "source": [
    "# Stage 4 AI training: Global hyperparameters\n",
    "\n",
    "This stage focuses on selecting the **optimal model's global hyperparameters**: activation function, optimizer and learning rate. Different rotational frames will be used for every configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b284a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages:\n",
    "import MLQDM.MLmodel as ML_MLmodel\n",
    "import MLQDM.timewindows as ML_twdw\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check available GPU:\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5217d20e",
   "metadata": {},
   "source": [
    "## Load original data and general parameters\n",
    "Load data from files (many segments) and store information in dataframes, one for each segment. The original data is in the **Laboratory rotational frame (RF1)**.\n",
    "\n",
    "There are two possible sets of target labels, coming for the 'linear approximation' of 'physical model' approaches regarding the interpolated positions. You must choose one as {interp} for the training stage:\n",
    "* **'lin_approx'** : linear approximation.\n",
    "* **'phys_model'** : physical model based on acceleration profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619836e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose Z-position interpolation method:\n",
    "interp = 'lin_approx' # 'phys_model' or 'lin_approx'\n",
    "\n",
    "# Prepare files information:\n",
    "data_path =  'Data/Final_t_BxByBz_zAut_LabFrame/' # Datafiles path\n",
    "gen_pars_path = 'ML_parameters/'\n",
    "\n",
    "# Load data, general hyperparameters and rotational frames:\n",
    "data, hypers, RFs = ML_MLmodel.load_data_and_gen_pars(\n",
    "    data_path,gen_pars_path,interp=interp,final_stage=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2129ad88-fade-4ef7-a4ff-9406cbef19f6",
   "metadata": {},
   "source": [
    "## Generate time windows\n",
    "\n",
    "### Load original data\n",
    "\n",
    "Each data segment is processed into time windows, which must have a fixed time length (or equivalently, fixed number of points) by default. However, as the original data is stored in the Time_Wdw object, it can be reshaped later.\n",
    "\n",
    "The distribution of training and testing datasets is chosen here. The validation dataset is included within the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92844d83-1669-489c-8791-6b3f97c67a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare time windows:\n",
    "wdw_pp = 40\n",
    "train_segm = [0,2,4] if interp == 'phys_model' else [2,3,4]\n",
    "t_wdws_train, t_wdws_test = ML_twdw.prepare_time_windows(\n",
    "    data,wdw_pp,train_segm=train_segm,\n",
    "    plot_instances=True,instances=10,start_wdw=570,stride_pp=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1c51c5-22bd-412b-8f25-fdadc996235a",
   "metadata": {},
   "source": [
    "### Global hyperparameters\n",
    "\n",
    "#### Previous stages\n",
    "\n",
    "From Stage 1 analysis, we've determined that only the full vector data, meaning all three $(Bx,By,Bz)$ magnetic components, is robust against rotations and has about 90% accuracy for position predictions using a 1-meter threshold.\n",
    "\n",
    "From Stage 2, we've determined that increasing the number of time window points is associated with better ML performance, up to a certain limit. Using 40 points (equal to 4s) is a good compromise between performance and complexity of the ML model. We also proved that for time windows longer than 2s (20 points), the ML model works much better if Convolutional Neural Networks (CNN) are combined with Dense Neural Networks (DNN).\n",
    "\n",
    "From Stage 3, we've determined the best main architecture for the ML algorithm: \n",
    "\n",
    "* Convolutional block: One-dimensional Convolutional layers (filter,kernel): [32,16] + [32,4]\n",
    "* Pooling layers: None\n",
    "* 1D-Conversion layer: Flattening\n",
    "* Dense layers (neurons): [1024] + [512]\n",
    "\n",
    "#### Current stage\n",
    "\n",
    "In this stage, we explore the ML model's global hyperparameters: learning rate, optimizer and activation function.\n",
    "\n",
    "* Activation_Function = ['relu','elu','tanh']\n",
    "* Optimizer = ['adam', 'adadelta', 'adamax']\n",
    "* Learning_Rate = [5e-2,1e-1,5e-3,1e-3,5e-4,1e-4,5e-5,1e-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb975bd-a351-4808-9d19-872c1f09b0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define additional hyperparameters:\n",
    "extra_hypers = {\n",
    "    \"Magnetic_Components\": ['Bx','By','Bz'],\n",
    "    \"Time_Window_pp\": wdw_pp,\n",
    "    \"Dropout_Fraction\": 0,\n",
    "    \"Convolutional_Network\": True,\n",
    "    \"Conv_Layers\": [[32,8],[32,4]],\n",
    "    \"Pool_Layers\": [None,None],\n",
    "    \"Dens_Layers\": [1024,512],\n",
    "    \"Flatten_Average\": True,\n",
    "    \"Dropout_Fraction\": 0,\n",
    "    \"Model_Name\": \"S4_C16_C4_NP_Flatten_D1024_D512\",\n",
    "}\n",
    "\n",
    "# Options for hyper-parameters:\n",
    "activ_opts = ['tanh'] #['relu','elu','tanh']\n",
    "optim_opts = ['adam'] #['adam', 'adadelta', 'adamax']\n",
    "lr_opts = [\n",
    "    1e1,\n",
    "    1e-0,\n",
    "    1e-1,\n",
    "    1e-2,\n",
    "    1e-3,\n",
    "    1e-4,\n",
    "    1e-5,\n",
    "    1e-6,\n",
    "    1e-7,\n",
    "    1e-8,\n",
    "    1e-9,\n",
    "    1e-10,\n",
    "    1e-11,\n",
    "    1e-12\n",
    "    ]\n",
    "\n",
    "# Options for seeds:\n",
    "seed_opts = [0,1,2]\n",
    "\n",
    "# Combine all general hyperparameters:\n",
    "gen_hyps = hypers | extra_hypers\n",
    "\n",
    "# Prepare rotational frame options:\n",
    "RF_opts = list(RFs.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c94518-bff9-43ac-b17b-bef33c22f937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare file path to export results:\n",
    "results_path = f'Results_{interp}/Train_s1s4s5_Test_s2s3/'\n",
    "# Prepare file path to check on already trained models and avoid repetitions:\n",
    "check_rep_model = f'Results_{interp}/Train_s1s4s5_Test_s2s3/Stage4_{interp}_all_Train_s1s4s5_Test_s2s3.csv'\n",
    "\n",
    "# Train all models:\n",
    "df_results = ML_MLmodel.train_stage4(\n",
    "    activ_opts,optim_opts,lr_opts,gen_hyps,RF_opts,\n",
    "    t_wdws_train,t_wdws_test,seed_opts,seed_opts,\n",
    "    results_path=results_path,interpolation=interp,\n",
    "    check_rep_model=check_rep_model,quick_timing_test=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416e76e6-1a4d-40b9-9a86-b3e35885903d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6388a3e4-27dd-4856-8a2b-fba9ec7bebbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7417a3d5-abbf-4c1c-a18f-120e1f68bde1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py12",
   "language": "python",
   "name": "py12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
