{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f111fbfc",
   "metadata": {},
   "source": [
    "# Stage 5 AI training: Fine architecture\n",
    "\n",
    "This stage focuses on selecting the ML model's **fine architecture**: number of Convolutional filters and Dense dropout fraction. Different rotational frames will be used for every fine architecture option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b284a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages:\n",
    "import MLQDM.MLmodel as ML_MLmodel\n",
    "import MLQDM.timewindows as ML_twdw\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check available GPU:\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5217d20e",
   "metadata": {},
   "source": [
    "## Load original data and general parameters\n",
    "Load data from files (many segments) and store information in dataframes, one for each segment. The original data is in the **Laboratory rotational frame (RF1)**.\n",
    "\n",
    "There are two possible sets of target labels, coming for the 'linear approximation' of 'physical model' approaches regarding the interpolated positions. You must choose one as {interp} for the training stage:\n",
    "* **'lin_approx'** : linear approximation.\n",
    "* **'phys_model'** : physical model based on acceleration profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619836e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose Z-position interpolation method:\n",
    "interp = 'lin_approx' # 'phys_model' or 'lin_approx'\n",
    "\n",
    "# Prepare files information:\n",
    "data_path =  'Data/Final_t_BxByBz_zAut_LabFrame/' # Datafiles path\n",
    "gen_pars_path = 'ML_parameters/'\n",
    "\n",
    "# Load data, general hyperparameters and rotational frames:\n",
    "data, hypers, RFs = ML_MLmodel.load_data_and_gen_pars(\n",
    "    data_path,gen_pars_path,interp=interp,final_stage=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2129ad88-fade-4ef7-a4ff-9406cbef19f6",
   "metadata": {},
   "source": [
    "## Generate time windows\n",
    "\n",
    "### Load original data\n",
    "\n",
    "Each data segment is processed into time windows, which must have a fixed time length (or equivalently, fixed number of points) by default. However, as the original data is stored in the Time_Wdw object, it can be reshaped later.\n",
    "\n",
    "The distribution of training and testing datasets is chosen here. The validation dataset is included within the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92844d83-1669-489c-8791-6b3f97c67a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare time windows:\n",
    "wdw_pp = 40\n",
    "train_segm = [0,2,4] if interp == 'phys_model' else [2,3,4]\n",
    "t_wdws_train, t_wdws_test = ML_twdw.prepare_time_windows(\n",
    "    data,wdw_pp,train_segm=train_segm,\n",
    "    plot_instances=True,instances=10,start_wdw=570,stride_pp=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9d897d-829b-441e-8228-e7253c3c3595",
   "metadata": {},
   "source": [
    "### Fine architecture\n",
    "\n",
    "#### Previous stages\n",
    "\n",
    "From Stage 1 analysis, we've determined that only the full vector data, meaning all three $(Bx,By,Bz)$ magnetic components, is robust against rotations and has about 90% accuracy for position predictions using a 1-meter threshold.\n",
    "\n",
    "From Stage 2, we've determined that increasing the number of time window points is associated with better ML performance, up to a certain limit. Using 40 points (equal to 4s) is a good compromise between performance and complexity of the ML model. We also proved that for time windows longer than 2s (20 points), the ML model works much better if Convolutional Neural Networks (CNN) are combined with Dense Neural Networks (DNN).\n",
    "\n",
    "From Stage 3, we've determined the best main architecture for the ML algorithm: \n",
    "\n",
    "* Convolutional block: One-dimensional Convolutional layers (filter,kernel): [32,16] + [32,4]\n",
    "* Pooling layers: None\n",
    "* 1D-Conversion layer: Flattening\n",
    "* Dense layers (neurons): [1024] + [512]\n",
    "\n",
    "From Stage 4, we've determined the best global hyperparameters:\n",
    "\n",
    "* Activation function: tanh\n",
    "* Optimizer: adam\n",
    "* Learning rate: 5e-4\n",
    "\n",
    "#### Current stage\n",
    "\n",
    "In this stage, we explore the ML model's fine architecture: number of filters in the two Convolutional layers and dropout fraction in the two Dense layers.\n",
    "\n",
    "* CNN filters ([1st layer,2nd layer]) = [[16,16], [32,16], [16,32], [32,32]]\n",
    "* Dropout Fraction (same in both layers) = [0, 0.2, 0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8616aa86-b6fa-4ff5-9586-8d10353e8d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define additional hyperparameters:\n",
    "extra_hypers = {\n",
    "    \"Magnetic_Components\": ['Bx','By','Bz'],\n",
    "    \"Time_Window_pp\": wdw_pp,\n",
    "    \"Dropout_Fraction\": 0,\n",
    "    \"Activation_Function\": 'relu',\n",
    "    \"Optimizer\": 'adam',\n",
    "    \"Convolutional_Network\": True,\n",
    "    \"Conv_Layers\": [[32,8],[32,4]],\n",
    "    \"Pool_Layers\": [None,None],\n",
    "    \"Dens_Layers\": [1024,512],\n",
    "    \"Flatten_Average\": True,\n",
    "    \"Dropout_Fraction\": 0,\n",
    "    \"Activation_Function\": 'tanh',\n",
    "    \"Optimizer\": 'adam',\n",
    "    \"Learning_Rate\": 1e-4,\n",
    "    \"Model_Name\": \"S5_C16_C4_NP_Flatten_D1024_D512\",\n",
    "}\n",
    "\n",
    "# Options for hyper-parameters:\n",
    "filter_opts = [[[16,8],[16,4]],\n",
    "               [[32,8],[16,4]],\n",
    "               [[16,8],[32,4]],\n",
    "               [[32,8],[32,4]]]\n",
    "drop_opts = [0, 0.2, 0.4]\n",
    "\n",
    "# Combine all general hyperparameters:\n",
    "gen_hyps = hypers | extra_hypers\n",
    "\n",
    "# Prepare rotational frame options:\n",
    "RF_opts = list(RFs.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7e6bcc-4fa3-468e-8527-213c393f1741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare file path to export results:\n",
    "results_path = f'Results_{interp}/Train_s1s4s5_Test_s2s3/'\n",
    "# Prepare file path to check on already trained models and avoid repetitions:\n",
    "check_rep_model = None#f'Results_{interp}/Train_s1s4s5_Test_s2s3/Stage5_{interp}_all_Train_s1s4s5_Test_s2s3.csv'\n",
    "\n",
    "# Train all models:\n",
    "df_results = ML_MLmodel.train_stage5(\n",
    "    filter_opts,drop_opts,gen_hyps,RF_opts,\n",
    "    t_wdws_train,t_wdws_test,interpolation=interp,\n",
    "    results_path=results_path,\n",
    "    check_rep_model=check_rep_model,quick_timing_test=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7417a3d5-abbf-4c1c-a18f-120e1f68bde1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
